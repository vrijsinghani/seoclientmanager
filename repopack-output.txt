This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2024-10-03T21:52:05.205Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
apps/
  common/
    tools/
      browser_tools.py
      crawl_website_search_tool.py
      crawl_website_tool.py
      ExaSearchTool.py
      google_suggestions_tool.py
      keyword_tools.py
      keywords_for_site_tool.py
      rag_tool.py
      retrieve_discoverydata_tool.py
      searxng_tool.py
      summarizer.py
      website_search_tool.py
    admin.py
    apps.py
    browser_tool.py
    chat_model_handler.py
    compression_manager.py
    content_loader.py
    models.py
    summarization_manager.py
    summarizer.py
    tests.py
    utils.py
    views.py
  seo_manager/
    admin.py
    apps.py
    forms.py
    google_analytics_service.py
    google_auth.py
    models.py
    services.py
    urls.py
    views_summarizer.py
    views.py
core/
  asgi.py
  settings.py
  urls.py
  wsgi.py
home/
  templatetags/
    admin_soft.py
    replace_value.py
  admin.py
  apps.py
  forms.py
  models.py
  tests.py
  urls.py
  utils.py
  views.py

================================================================
Repository Files
================================================================

================
File: apps/common/tools/browser_tools.py
================
import json
import os

import requests
from langchain.tools import tool
from unstructured.partition.html import partition_html
from trafilatura import fetch_url, extract, sitemaps, spider
from summarizer import summarize

class BrowserTools():

  @tool("Scrape and summarize website content")
  def scrape_and_summarize_website(website):
    """Useful to scrape and summarize a website content, just pass a string with
    only the full url, no need for a final slash `/`, eg: https://google.com or https://clearbit.com/about-us"""
    url = f"https://browserless.neuralami.com/content?token={os.environ['BROWSERLESS_API_KEY']}"
    payload = json.dumps({"url": website})
    headers = {'cache-control': 'no-cache', 'content-type': 'application/json'}
    print(f"Browsin': {website}")
    response = requests.request("POST", url, headers=headers, data=payload)
    content = extract(response.text)
    summary = summarize(content)
    print(f"summary: '{summary}'")
    content = summary

    return f'\nSummary of {website}: {content}\n'

  @tool("Scrape website content")
  def scrape_website(website):
    """Useful to scrape website content, just pass a string with
    only the full url, no need for a final slash `/`, eg: https://google.com or https://clearbit.com/about-us"""
    url = f"https://browserless.neuralami.com/content?token={os.environ['BROWSERLESS_API_KEY']}"
    payload = json.dumps({"url": website})
    headers = {'cache-control': 'no-cache', 'content-type': 'application/json'}
    print(f"Browsin': {website}")
    response = requests.request("POST", url, headers=headers, data=payload)
    content = extract(response.text)
    return f'\nContent of {website}: {content}\n'

================
File: apps/common/tools/crawl_website_search_tool.py
================
from typing import Optional, Type, Any, List

from embedchain.models.data_type import DataType
from pydantic.v1 import BaseModel, Field

from crewai_tools import RagTool

from tools.custom_browserless_loader import CustomBrowserlessLoader
from trafilatura import fetch_url, extract, sitemaps, spider

import os

class FixedCrawlWebsiteSearchToolSchema(BaseModel):
    """Input for CrawlWebsiteTool."""

    search_query: str = Field(
        ...,
        description = "Mandatory search query  you want to use to search a specific website and it's internal pages."
    )
    pass

class CrawlWebsiteSearchToolSchema(FixedCrawlWebsiteSearchToolSchema):
    """Input for CrawlWebsiteTool."""
    website: str = Field(
        ..., 
        description="Mandatory website url to crawl and read content")

class CrawlWebsiteSearchTool(RagTool):
    name: str = "Crawl and search website content"
    description: str = "A tool that can be used to crawl a website and read its content, including content from internal links on the same page."
    args_schema: Type[BaseModel] = CrawlWebsiteSearchToolSchema
    # website: Optional[str] = None
    # api_token: str = ""
    # base_url: str = ""

    def __init__(self, website: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        # self.api_token = os.environ.get("BROWSERLESS_API_KEY")
        # self.base_url = os.environ.get("BROWSERLESS_BASE_URL")
        if website is not None:
            self._crawl_website(website)
            self.description = f"A tool that can be used to crawl {website} and read its content, including content from internal links on the same page."
            self.args_schema = FixedCrawlWebsiteSearchToolSchema

    def add(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        kwargs["data_type"] = DataType.WEB_PAGE
        super().add(*args, **kwargs)

    def _crawl_website(self, url: str) -> str:
        links_to_visit = self._get_links_to_visit(url)
        print(f"Reading {len(links_to_visit)} pages.")
        for link in links_to_visit:
            try:
                self.add(link) # Assuming this is a method that adds the link to some data structure
            except Exception as e:
                print(f"Failed to read page at '{link}'. Error: {e}")

        
    def _get_links_to_visit(self, url: str) -> List[str]:
        sitemap_links = sitemaps.sitemap_search(url)
        # if sitemap_links:
        if 0:
            print(f"Found {len(sitemap_links)} pages from sitemap.")
            return sitemap_links
        else:
            _, known_urls = spider.focused_crawler(url, max_seen_urls=10, max_known_urls=50)
            print(f"Found {len(known_urls)} from crawling the website.")
            return list(known_urls)

    def _before_run(
        self,
        query: str,
        **kwargs: Any,
    ) -> Any:
        if "website" in kwargs:
            self.add(kwargs["website"])

    def _run(
        self,
        search_query: str,
        **kwargs: Any,
    )-> Any:
        return super()._run(query=search_query)

================
File: apps/common/tools/crawl_website_tool.py
================
import requests
from bs4 import BeautifulSoup
from typing import Optional, Type, Any, List
from pydantic.v1 import BaseModel, Field
from crewai_tools import BaseTool
from urllib.parse import urljoin
from trafilatura import fetch_url, extract, sitemaps, spider

class FixedCrawlWebsiteToolSchema(BaseModel):
    """Input for CrawlWebsiteTool."""
    pass

class CrawlWebsiteToolSchema(FixedCrawlWebsiteToolSchema):
    """Input for CrawlWebsiteTool."""
    website_url: str = Field(..., description="Mandatory website url to crawl and read content")

class CrawlWebsiteTool(BaseTool):
    name: str = "Crawl and read website content"
    description: str = "A tool that can be used to crawl a website and read its content, including content from internal links on the same page."
    args_schema: Type[BaseModel] = CrawlWebsiteToolSchema
    website_url: Optional[str] = None
    headers: Optional[dict] = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',
        'Accept-Language': 'en-US,en;q=0.5',
        'Referer': 'https://www.google.com/'
    }

    def __init__(self, website_url: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if website_url is not None:
            self.website_url = website_url
            self.description = f"A tool that can be used to crawl {website_url} and read its content, including content from internal links on the same page."
            self.args_schema = FixedCrawlWebsiteToolSchema

    def _run(self, **kwargs: Any) -> str:
        website_url = kwargs.get('website_url', self.website_url)
        print(f"Processing {website_url}")
        content = self._crawl_website(website_url)
        return content

    def _crawl_website(self, url: str) -> str:
        links_to_visit = self._get_links_to_visit(url)
        content = ""
        print(f"Reading {len(links_to_visit)} pages.")
        for link in links_to_visit:
            page_content = self._fetch_and_extract_content(link)
            content += page_content
        
        return content

    def _get_links_to_visit(self, url: str) -> List[str]:
#        sitemap_links = sitemaps.sitemap_search(url)
        sitemap_links = []
        if sitemap_links:
            print(f"Found {len(sitemap_links)} pages from sitemap.")
            return sitemap_links
        else:
            _, known_urls = spider.focused_crawler(url, max_seen_urls=10, max_known_urls=1000)
            print(f"Found {len(known_urls)} from crawling the website.")
            return list(known_urls)

    def _fetch_and_extract_content(self, url: str) -> str:
        html_content = fetch_url(url)
        if html_content:
            extracted_content = f"---link: {url}\n{extract(html_content,url=url)}\n---page-end---\n"
            return extracted_content or ""
        else:
            return ""

================
File: apps/common/tools/ExaSearchTool.py
================
import os
from exa_py import Exa
from langchain.agents import tool

class ExaSearchTool:
	@tool
	def search(query: str):
		"""Search for a webpage based on the query."""
		return ExaSearchTool._exa().search(f"{query}", use_autoprompt=True, num_results=3)

	@tool
	def find_similar(url: str):
		"""Search for webpages similar to a given URL.
		The url passed in should be a URL returned from `search`.
		"""
		return ExaSearchTool._exa().find_similar(url, num_results=3)

	@tool
	def get_contents(ids: str):
		"""Get the contents of a webpage.
		The ids must be passed in as a list, a list of ids returned from `search`.
		"""
		ids = eval(ids)
		contents = str(ExaSearchTool._exa().get_contents(ids))
		print(contents)
		contents = contents.split("URL:")
		contents = [content[:1000] for content in contents]
		return "\n\n".join(contents)

	def tools():
		return [ExaSearchTool.search, ExaSearchTool.find_similar, ExaSearchTool.get_contents]

	def _exa():
		return Exa(api_key=os.environ["EXA_API_KEY"])

================
File: apps/common/tools/google_suggestions_tool.py
================
from crewai_tools import tool
import requests
import xml.etree.ElementTree as ET

@tool("Google Suggestions")
def google_suggestions_tool(argument: str) -> str:
    """Retrieve Google search suggestions for a given keyword."""
    # Parse the argument to extract the keyword and other parameters
    keyword = argument.split(",")[0].strip()
    country_code = argument.split(",")[1].strip() if "," in argument else "us"

    # Build the Google Search query URL
    search_query = f"is {keyword}"
    google_search_url = f"http://google.com/complete/search?output=toolbar&gl={country_code}&q={search_query}"

    # Call the URL and read the data
    result = requests.get(google_search_url)
    tree = ET.ElementTree(ET.fromstring(result.content))
    root = tree.getroot()

    # Extract the suggestions from the XML response
    suggestions = []
    for suggestion in root.findall('CompleteSuggestion'):
        question = suggestion.find('suggestion').attrib.get('data')
        suggestions.append(question)

    # Return the suggestions as a comma-separated string
    return ", ".join(suggestions)

================
File: apps/common/tools/keyword_tools.py
================
import os
import requests
from langchain.tools import BaseTool
from pydantic.v1 import BaseModel, Field
from typing import Type, Optional, List, Dict, Any, Tuple


class KeywordsInput(BaseModel):
    keywords: List[str] = Field(description="list of keywords")
    filters: List[Tuple[str, str, float]] = Field(description="list of filters")

class KeywordsForSiteTool(BaseTool):
    name = "keywords_for_site"
    description = "Provides a list of keywords relevant to the target domain. Each keyword is supplied with relevant categories, search volume data for the last month, cost-per-click, competition, and search volume trend values for the past 12 months"

    def _run(self, target: str) -> str:
        login, password = KeywordTools._dataforseo_credentials()
        cred = (login, password)
        url = "https://api.dataforseo.com/v3/keywords_data/google_ads/keywords_for_site/live"
        payload = [
            {
                "target": target,
                "language_code": "en",
                "location_code": 2840,
            }
        ]
        headers = {"Content-Type": "application/json"}
        response = requests.post(url, json=payload, headers=headers, auth=cred)
        response.raise_for_status()  # Raise an exception for non-2xx status codes
        results = response.json()
        return results["tasks"][0]["result"]

    def _arun(self, target: str) -> str:
        raise NotImplementedError("KeywordsForSiteTool does not support async")

class KeywordSuggestionsTool(BaseTool):
    name = "keyword_suggestions"
    description = "Provides a list of keywords relevant to the target domain. Each keyword is supplied with relevant categories, search volume data for the last month, cost-per-click, competition, and search volume trend values for the past 12 months"

    def _run(self, seed_keyword: str, filters: Optional[List] = None) -> str:
        login, password = KeywordTools._dataforseo_credentials()
        cred = (login, password)
        url = "https://api.dataforseo.com/v3/dataforseo_labs/google/keyword_suggestions/live"
        payload = [
            {
                "keyword": seed_keyword,
                "location_code": 2840,
                "language_code": "en",
                "include_serp_info": True,
                "include_seed_keyword": True,
                "limit": 50,
            }
        ]
        if filters:
            payload[0]["filters"] = filters
        headers = {"Content-Type": "application/json"}
        response = requests.post(url, json=payload, headers=headers, auth=cred)
        response.raise_for_status()  # Raise an exception for non-2xx status codes
        results = response.json()
        #return results["tasks"][0]["result"]
        return results

    def _arun(self, seed_keyword: str, filters: Optional[List] = None) -> str:
        raise NotImplementedError("KeywordSuggestionsTool does not support async")

class KeywordIdeasTool(BaseTool):
    name = "keyword_ideas"
    description = "Provides search terms that are relevant to the product or service categories of the specified keywords. The algorithm selects the keywords which fall into the same categories as the seed keywords specified"
    args_schema: Type[BaseModel] = KeywordsInput

    def _run(self, keywords: List[str], filters: List[str]=None) -> str:
        
        
        login, password = KeywordTools._dataforseo_credentials()
        cred = (login, password)
        url = "https://api.dataforseo.com/v3/dataforseo_labs/google/keyword_ideas/live"
        payload = [
            {
                "keywords": keywords,
                "location_code": 2840,
                "language_code": "en",
                "include_serp_info": True,
                "limit": 100,
          }
        ]
        payload[0]["ordery_by"]="keyword_info.search_volume,desc"
        if filters:
            payload[0]["filters"] = filters
        headers = {"Content-Type": "application/json"}
        response = requests.post(url, json=payload, headers=headers, auth=cred)
        response.raise_for_status()  # Raise an exception for non-2xx status codes
        results = response.json()
        return results

    def _arun(self, tool_input: Dict[str, Any]) -> Dict:
        raise NotImplementedError("KeywordSuggestionsTool does not support async")

class KeywordTools:
    @staticmethod
    def tools():
        return [KeywordsForSiteTool(), KeywordSuggestionsTool(), KeywordIdeasTool()]

    @staticmethod
    def _dataforseo_credentials():
        login = os.environ["DATAFORSEO_LOGIN"]
        password = os.environ["DATAFORSEO_PASSWORD"]
        return login, password

================
File: apps/common/tools/keywords_for_site_tool.py
================
import os
import requests
from crewai import Agent
from langchain.tools import tool

@tool("DataForSEO Keywords for Site")
def keywords_for_site_tool(target: str) -> str:
    """
    Retrieves a list of SEO keywords relevant to the specified site using the DataForSEO API.
    """
    login = os.environ["DATAFORSEO_LOGIN"]
    password = os.environ["DATAFORSEO_PASSWORD"]
    cred = (login, password)
    url = "https://api.dataforseo.com/v3/dataforseo_labs/google/keywords_for_site/live"

    payload = [
        {
            "target": target,
            "language_code": "en",
            "location_code": 2840,
        }
    ]

    headers = {"Content-Type": "application/json"}

    response = requests.post(url, json=payload, headers=headers, auth=cred)
    results = response.json()

    # Process the results and return the desired output
    # ...

    return results

================
File: apps/common/tools/rag_tool.py
================
from abc import ABC, abstractmethod
from typing import Any

from pydantic import BaseModel, Field, model_validator

from crewai_tools.tools.base_tool import BaseTool


class Adapter(BaseModel, ABC):
    class Config:
        arbitrary_types_allowed = True

    @abstractmethod
    def query(self, question: str) -> str:
        """Query the knowledge base with a question and return the answer."""

    @abstractmethod
    def add(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        """Add content to the knowledge base."""


class RagTool(BaseTool):
    class _AdapterPlaceholder(Adapter):
        def query(self, question: str) -> str:
            raise NotImplementedError

        def add(self, *args: Any, **kwargs: Any) -> None:
            raise NotImplementedError

    name: str = "Knowledge base"
    description: str = "A knowledge base that can be used to answer questions."
    summarize: bool = False
    adapter: Adapter = Field(default_factory=_AdapterPlaceholder)
    config: dict[str, Any] | None = None

    @model_validator(mode="after")
    def _set_default_adapter(self):
        if isinstance(self.adapter, RagTool._AdapterPlaceholder):
            from embedchain import App

            from crewai_tools.adapters.embedchain_adapter import EmbedchainAdapter

            app = App.from_config(config=self.config) if self.config else App()
            self.adapter = EmbedchainAdapter(
                embedchain_app=app, summarize=self.summarize
            )

        return self

    def add(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        self.adapter.add(*args, **kwargs)

    def _run(
        self,
        query: str,
        **kwargs: Any,
    ) -> Any:
        self._before_run(query, **kwargs)

        return f"Relevant Content:\n{self.adapter.query(query)}"

    def _before_run(self, query, **kwargs):
        pass

================
File: apps/common/tools/retrieve_discoverydata_tool.py
================
import os
import psycopg2
from typing import Optional, List
from dotenv import load_dotenv

from crewai_tools import tool

# Load environment variables from .env file
load_dotenv()

@tool("PostgreSQL DiscoveryData Retrieval")
def pg_data_retrieval_tool(
    company_name: str,
) -> List[dict]:
    """
    A tool to retrieve discovery data for a prospective client based on company name from database, useful for company background and expectations.

    To use this tool, provide the following input:
    - company_name: The name of the company to filter the data

    The tool will return the queried data as a list of dictionaries.
    """
    try:
        db_protocol = os.environ.get("DB_PROTOCOL")
        db_username = os.environ.get("DB_USERNAME")
        db_password = os.environ.get("DB_PASSWORD")
        db_host = os.environ.get("DB_HOST")
        db_name = os.environ.get("DB_NAME")
        table_name = os.environ.get("DB_DISCOVERY")

        conn = psycopg2.connect(
            f"{db_protocol}://{db_username}:{db_password}@{db_host}/{db_name}"
        )
        cursor = conn.cursor()

        # Get the field names from the database table
        cursor.execute(f"SELECT * FROM {table_name} WHERE 1=0")
        field_names = [desc[0] for desc in cursor.description]

        query = f"SELECT * FROM {table_name} WHERE company_name like '{company_name}'"
        cursor.execute(query)
        result = cursor.fetchall()

        if result:
            # Convert the result to a list of dictionaries
            data = [dict(zip(field_names, row)) for row in result]
            return data
        else:
            return []

    except (Exception, psycopg2.Error) as e:
        return [{"error": str(e)}]

    finally:
        # Close the database connection
        if conn:
            cursor.close()
            conn.close()

================
File: apps/common/tools/searxng_tool.py
================
import os
import requests
import json
from typing import Any, Type
from pydantic.v1 import BaseModel, Field
from crewai_tools.tools.base_tool import BaseTool

class SearxNGToolSchema(BaseModel):
    """Input schema for SearxNGSearchTool."""
    search_query: str = Field(..., description="The search query to be used.")

class SearxNGSearchTool(BaseTool):
    name: str = "Search the internet"
    description: str = "Searches the internet displaying titles, links, snippets, engines, and categories."
    args_schema: Type[BaseModel] = SearxNGToolSchema
    search_url: str = "https://search.neuralami.com"
    n_results: int = None
    
    def _run(
		self, 
		search_query: str, 
		**kwargs: Any
		) -> Any:
        payload = {        
            'q': search_query,
            'format': 'json',
            'pageno': '1',
            'language': 'en-US'
        }
        response = requests.get(self.search_url, params=payload)
        if response.ok:
            results = response.json()['results']
            formatted_results = []
            for result in results:
                try:
                    engines = ', '.join(result['engines']) if 'engines' in result else 'N/A'
                    formatted_results.append('\n'.join([
                            f"Title: {result.get('title', 'No Title')}",
                            f"Link: {result.get('url', 'No Link')}",
                            f"Score: {result.get('score', 'No Score')}",
                            f"Snippet: {result.get('content', 'No Snippet')}",
                            f"Engines: {engines}",
                            f"Category: {result.get('category', 'No Category')}",
                            "---"
                    ]))
                except KeyError as e:
                    print(f"Skipping an entry due to missing key: {e}")
                    continue

            content = '\n'.join(formatted_results)
            return f"Search results:\n{content}"
        else:
            return f"Failed to fetch search results. Status code: {response.status_code}"

================
File: apps/common/tools/summarizer.py
================
from langchain.chat_models import ChatOllama
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain_core.output_parsers import StrOutputParser

def summarize(query, base_url="http://192.168.30.100:11434"):
    """
    Generate a response to a user's query using the ChatOllama model.

    Args:
        query (str): The user's query.
        base_url (str, optional): The base URL for the API endpoint. Defaults to "https://api.example.com/v1/chat".

    Returns:
        str: The response to the user's query, formatted in Markdown.
    """
    
    # Initialize the ChatOllama model with the base_url parameter
    llm = ChatOllama(model="mistral", base_url=base_url)

    # Define a chat prompt template
    prompt = ChatPromptTemplate.from_messages([
    ("system", "Extract all relevant facts from the text."),
    ("human", "{query}"),
    ])

    # prompt = ChatPromptTemplate(
    #     messages=[
    #         SystemMessagePromptTemplate(
    #             prompt=("You are a helpful AI assistant for summarization. "
    #                     "Provide a concise summary of the users input, just the summary, no extra commentary.")
    #         ),
    #         HumanMessagePromptTemplate(input_variables=["query"]),
    #     ]
    # )
    chain = prompt | llm | StrOutputParser()
    # Define an output parser to handle Markdown responses
    # Generate a response to the user's query
    response = chain.invoke({'query':query})
    result = response

    return result

================
File: apps/common/tools/website_search_tool.py
================
from typing import Any, Optional, Type

from embedchain.models.data_type import DataType
from pydantic.v1 import BaseModel, Field

from ..rag.rag_tool import RagTool


class FixedWebsiteSearchToolSchema(BaseModel):
    """Input for WebsiteSearchTool."""

    search_query: str = Field(
        ...,
        description="Mandatory search query you want to use to search a specific website",
    )


class WebsiteSearchToolSchema(FixedWebsiteSearchToolSchema):
    """Input for WebsiteSearchTool."""

    website: str = Field(
        ..., description="Mandatory valid website URL you want to search on"
    )


class WebsiteSearchTool(RagTool):
    name: str = "Search in a specific website"
    description: str = "A tool that can be used to semantic search a query from a specific URL content."
    args_schema: Type[BaseModel] = WebsiteSearchToolSchema

    def __init__(self, website: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if website is not None:
            self.add(website)
            self.description = f"A tool that can be used to semantic search a query from {website} website content."
            self.args_schema = FixedWebsiteSearchToolSchema

    def add(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        kwargs["data_type"] = DataType.WEB_PAGE
        super().add(*args, **kwargs)

    def _before_run(
        self,
        query: str,
        **kwargs: Any,
    ) -> Any:
        if "website" in kwargs:
            self.add(kwargs["website"])

================
File: apps/common/admin.py
================
from django.contrib import admin

# Register your models here.

================
File: apps/common/apps.py
================
from django.apps import AppConfig


class CommonConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'apps.common'

================
File: apps/common/browser_tool.py
================
import json
import os

import requests
from langchain.tools import tool
from unstructured.partition.html import partition_html
from trafilatura import fetch_url, extract, sitemaps, spider

class BrowserTools():

  @tool("Scrape website content")
  def scrape_website(website):
    """Useful to scrape website content, just pass a string with
    only the full url, no need for a final slash `/`, eg: https://google.com or https://clearbit.com/about-us"""
    url = f"https://browserless.rijsinghani.us/content?token={os.environ['BROWSERLESS_API_KEY']}"
    payload = json.dumps({"url": website})
    headers = {'cache-control': 'no-cache', 'content-type': 'application/json'}
    print(f"Browsin': {website}")
    response = requests.request("POST", url, headers=headers, data=payload)
    content = extract(response.text)
    return f'\nContent of {website}: {content}\n'

================
File: apps/common/chat_model_handler.py
================
from langchain_openai import ChatOpenAI
import openai
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain.schema import AIMessage, HumanMessage, SystemMessage

class ChatModelHandler:
    def __init__(self, model_name: str):
        self.model_name = model_name
        self.chat_model = ChatOpenAI(model=model, base_url=settings.OPENAI_API_BASE, temperature=0.05)
        self.summarize_prompt = self._create_summarize_prompt()

    def _create_summarize_prompt(self) -> ChatPromptTemplate:
        """ Create a prompt template for summarization """
        system_message_prompt = SystemMessagePromptTemplate.from_template(
            "You are an AI assistant that summarizes text while preserving key details, using markdown formatting."
        )
        human_message_prompt = HumanMessagePromptTemplate.from_template("{text}")
        return ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])

    def _generate_messages(self, query: str) -> list:
        """ Generate messages for the chat model based on the query """
        human_message = HumanMessage(content=self.summarize_prompt.format_prompt(text=query).to_messages()[1].content)
        return [human_message]

    def generate_response(self, query: str) -> str:
        """ Generate a response from the chat model based on the query """
        messages = self._generate_messages(query)
        response = self.chat_model(messages)
        return response.content

================
File: apps/common/compression_manager.py
================
from .utils import tokenize, get_llm,  TokenCounterCallback
from langchain.text_splitter import TokenTextSplitter
from langchain.prompts.chat import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import tiktoken
from django.conf import settings
import logging
from langchain.callbacks.manager import CallbackManager
import os
import errno

class CompressionManager:
    def __init__(self, model_name:str, task_instance = None):
        self.tokenizer = tiktoken.get_encoding("cl100k_base")
        #self.llm=get_llm(model_name, temperature=0.0)
        self.model_name = model_name
        self.task_instance = task_instance
        self.llm, self.token_counter_callback = get_llm(model_name, temperature=0.0)

 
    
    def compress_content(self, content: str, max_tokens: int) -> str:
        content_tokens = tokenize(content, self.tokenizer)
        #logging.info(f"Compressing content: {len(content)} chars and {content_tokens} tokens")
        if content_tokens < 20:
            return content,0,0
        else:        
            logging.info(f"Compressing content: {len(content)} chars and {content_tokens} tokens and {max_tokens} max tokens.")
            return self._compress_iteratively(content, max_tokens)

    def _compress_iteratively(self, content: str, max_tokens: int) -> str:
        """ Compress content iteratively until it fits within max_tokens """
        chunk_size = int(max_tokens) // 3 # max_tokens #* 3 # 3x the max_tokens -> if split with chars
        overlap = 25
        text_splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)
        logging.info(f"Chunk size: {chunk_size} tokens")
        compress_prompt = ChatPromptTemplate.from_messages([
            ("human", """
1. Carefully read through the text and take detailed bullet point notes.
2. Focus on including every detail that impacts comprehension while avoiding superficial information or tangents.
3. Use bullet points, ordered lists, subbullets, or headings as appropriate to structure your notes.
4. No preambles, post ambles, summaries, just the notes.
5. Write at a 9th grade level.
\n\n```{content}```\n\n""")
        ])

        compress_chain = compress_prompt| self.llm | StrOutputParser()

        compressed_chunks = []
        chunks = text_splitter.split_text(content)
        num_chunks = len(chunks)
        iteration = 1

        last_iteration_size = tokenize(content,self.tokenizer)
        path=f'{settings.DOWNLOAD_FOLDER}/summarizer/compress_content-{str(iteration)}'
        if not os.path.exists(path):
            try:
                os.makedirs(os.path.dirname(path))
                logging.info("Created directory for compressed content")
            except FileExistsError:
                pass
        while True:
        #if True: # temporary to only do 1 pass
            #logging.info(f"Compression iteration {iteration} with {len(chunks)} chunks...")

            self.task_instance.update_state(
                state=f'reading content...',
                meta={'current_chunk': 0, 'total_chunks': num_chunks}
            )
            current_chunk = 0
            for chunk in chunks:
                #logging.info(f"Compressing chunk of length {tokenize(chunk,self.tokenizer)} tokens...")
                current_chunk += 1
                compressed_chunk = compress_chain.invoke({'content':chunk})
                #logging.info(f"Compressed chunk: {current_chunk} of {num_chunks} chunks of length {tokenize(compressed_chunk, self.tokenizer)} tokens...")
                self.task_instance.update_state(
                    state='processing',
                    meta={'current_chunk': current_chunk, 'total_chunks': num_chunks}
                )
                with open(f'{settings.DOWNLOAD_FOLDER}/summarizer/chunk-{current_chunk}-{iteration}','w') as f:
                    f.write(chunk)
                with open(f'{settings.DOWNLOAD_FOLDER}/summarizer/compressed-chunk-{current_chunk}-{iteration}','w') as f:
                    f.write(compressed_chunk)
                    
                

                compressed_chunks.append(compressed_chunk)

            compressed_content = "\n".join(compressed_chunks)
            token_count = tokenize(compressed_content, self.tokenizer)
            with open(f'{settings.DOWNLOAD_FOLDER}/summarizer/compress_content-{iteration}','w') as f:
                f.write(compressed_content)
                
            if token_count <= max_tokens or token_count > .75*last_iteration_size:
                break
            else:
                chunks = text_splitter.split_text(compressed_content)
                compressed_chunks = []
                num_chunks= len(chunks)
                iteration += 1
                last_iteration_size = token_count

        input_tokens = self.token_counter_callback.input_tokens
        output_tokens = self.token_counter_callback.output_tokens
        logging.info(f"Compression Input tokens: {input_tokens}, output tokens: {output_tokens}")
        return compressed_content, input_tokens, output_tokens

================
File: apps/common/content_loader.py
================
from .utils import is_pdf_url, is_youtube, is_stock_symbol
from .browser_tool import BrowserTools
from langchain_community.document_loaders import YoutubeLoader, PyMuPDFLoader
import logging
from sec_edgar_downloader import Downloader
import os
from bs4 import BeautifulSoup
from django.conf import settings

logger = logging.getLogger(__name__)

class ContentLoader:
    def __init__(self):
        self.browser_tool = BrowserTools()

    def load_content(self, query: str) -> str:
        """ Load and return content from a URL """
        logging.info("Loading content")
        if len(query) > 500:
            logger.info("Content too long to be anything but text")
            return query 
        if query.startswith("http"):
            url = query
            if is_youtube(url):
                logger.info(f"Loading content from YouTube: {url}")
                return self._load_from_youtube(url)
            elif is_pdf_url(url):
                logger.info(f"Loading content from PDF: {url}")
                return self._load_from_pdf(url)
            else:
                logger.info(f"Loading content from website: {url}")
                return self.browser_tool.scrape_website(url)
        elif is_stock_symbol(query):
                logger.info(f"Loading content from SEC EDGAR: {query}")
                return self._load_from_sec(query)
        else:
            logger.info("Loading as text")
            return query

    def _load_from_youtube(self, url: str) -> str:
        loader = YoutubeLoader.from_youtube_url(url)
        docs = loader.load()
        page_content = "".join(doc.page_content for doc in docs)
        metadata = docs[0].metadata
        # Create output string with metadata and page_content
        output = f"Title: {metadata.get('title')}\n\n"
        output += f"Description: {metadata.get('description')}\n\n"
        output += f"View Count: {metadata.get('view_count')}\n\n"
        output += f"Author: {metadata.get('author')}\n\n"
        output += f"Category: {metadata.get('category')}\n\n"
        output += f"Source: {metadata.get('source')}\n\n"
        output += f"Page Content:\n{page_content}"
        return output

    def _load_from_pdf(self, url: str) -> str:
        # Simulated PDF content loading method
        loader = PyMuPDFLoader(url)
        docs = loader.load()
        return "".join(doc.page_content for doc in docs)

    def _load_from_sec(self, query: str) -> str:
        """ Load and return content from SEC EDGAR """
        # Provide a company name and email address to comply with SEC EDGAR's fair access policy
        company_name = settings.COMPANY_NAME
        email_address = settings.EMAIL_ADDRESS

        # Create a Downloader instance with the specified download folder
        download_folder = settings.DOWNLOAD_FOLDER + "/sec-edgar-files"
        
        if not os.path.exists (download_folder):
            try:
                 os.makedirs (download_folder)
            except FileExistsError:
                pass
                  
        
        dl = Downloader(company_name, email_address, download_folder)

        num_filings_downloaded = dl.get("10-K", query, limit=1, download_details=True)
        logging.info(f"Downloaded {num_filings_downloaded} 10-K filing(s) for {query}.")

        print(f"Downloaded {num_filings_downloaded} 10-K filing(s) for {query}.")

        # Access the downloaded HTML filing
        if num_filings_downloaded > 0:
            logging.info("getting filings dir")
            filings_dir = os.path.join(download_folder, "sec-edgar-filings", query, "10-K")
            filing_subdirs = os.listdir(filings_dir)
            # latest_filing_subdir = sorted(filing_subdirs)[-1]
            # latest_filing_path = os.path.join(filings_dir, latest_filing_subdir, "primary-document.html")
            logging.info("getting latest_filings_subdir")
            latest_filing_subdir = sorted(filing_subdirs)[-1]
            # Convert set to string if necessary
            if not isinstance(latest_filing_subdir, str):
                latest_filing_subdir = str(latest_filing_subdir)
            logging.info("getting latest_filing_path")
            latest_filing_path = os.path.join(filings_dir, latest_filing_subdir, "primary-document.html")

            
            
            with open(latest_filing_path, "r") as f:
                html_content = f.read()
            
            # Parse the HTML content using BeautifulSoup
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # Extract the text content
            text_content = soup.get_text()
            
            return text_content

================
File: apps/common/models.py
================
from django.db import models

# Create your models here.
        
# Don't remove this mark
### ### Below code is Generated ### ###

from django.db import models

class RefundedChoices(models.TextChoices):
	YES = 'YES', 'Yes'
	NO = 'NO', 'No'

class CurrencyChoices(models.TextChoices):
	USD = 'USD', 'USD'
	EUR = 'EUR', 'EUR'
	
class Sales(models.Model):
	ID = models.AutoField(primary_key=True)
	Product = models.TextField(blank=True, null=True)
	BuyerEmail = models.EmailField(blank=True, null=True)
	PurchaseDate = models.DateField(blank=True, null=True)
	Country = models.TextField(blank=True, null=True)
	Price = models.FloatField(blank=True, null=True)
	Refunded = models.CharField(max_length=20, choices=RefundedChoices.choices, default=RefundedChoices.NO)
	Currency = models.CharField(max_length=10, choices=CurrencyChoices.choices, default=CurrencyChoices.USD)
	Quantity = models.IntegerField(blank=True, null=True)

================
File: apps/common/summarization_manager.py
================
from .utils import tokenize, get_llm
from langchain.text_splitter import TokenTextSplitter
from langchain.prompts.chat import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import tiktoken
from django.conf import settings
import logging
from langchain.callbacks.manager import CallbackManager
from .utils import tokenize, get_llm,  TokenCounterCallback
from django.utils import timezone

class SummarizationManager:
    def __init__(self, model_name:str, task_instance = None):
        self.tokenizer = tiktoken.get_encoding("cl100k_base")
        #self.llm=get_llm(model_name, temperature=0.0)
        self.model_name = model_name
        self.task_instance = task_instance
        self.llm, self.token_counter_callback = get_llm(model_name, temperature=0.0)    
        
    def summarize_content(self, content: str) -> str:
        
        content_tokens = tokenize(content, self.tokenizer)
        #logging.info(f'summarize_content {content_tokens} tokens: {content[:100]}')

        if content_tokens < 20:
            return f"##### TITLE: {content}",0,0
        todays_date=timezone.now().strftime("%Y-%m-%d")
        summarize_prompt = ChatPromptTemplate.from_messages([
            ("human", 
            """
Rewrite this text in the style of a textbook chapter for 9th graders.
                Text:{content}                   
            """),
        ])

        summarize_chain = summarize_prompt| self.llm | StrOutputParser()

        self.task_instance.update_state(
            state='summarizing content',
            meta={'current_chunk': 0, 'total_chunks': 1}           
        )

        summary = summarize_chain.invoke({'content':content, 'date':todays_date})

        input_tokens = self.token_counter_callback.input_tokens
        output_tokens = self.token_counter_callback.output_tokens
        #logging.info(f"Summarization Input tokens: {input_tokens}, output tokens: {output_tokens}")
        return summary, input_tokens, output_tokens

================
File: apps/common/summarizer.py
================
from langchain_community.chat_models import ChatOllama
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain_core.output_parsers import StrOutputParser
import re
import tiktoken

from langchain_community.document_loaders import YoutubeLoader
import io
from .browser_tool import BrowserTools
from django.utils import timezone
from apps.seo_manager.models import SummarizerUsage
from langchain.text_splitter import TokenTextSplitter

class Summarizer:
    def __init__(self):
        self.llm_tokens_sent=0
        self.llm_tokens_r=0
        self.encoder=tiktoken.get_encoding("gpt2")

    # def summarize_nlp(self, text):
    #     """
    #     Summarize a given text using TextRank algorithm.

    #     Args:
    #         text (str): Input text to be summarized.
    #         num_sentences (int, optional): Number of sentences to include in the summary. Defaults to 5.

    #     Returns:
    #         str: Summarized text.
    #     """
    #     # Preprocessing
    #     lemmatizer = WordNetLemmatizer()
    #     stop_words = set(stopwords.words('english'))

    #     tokens = word_tokenize(text.lower())
    #     tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]
    #     text = ' '.join(tokens)

    #     # Sentence tokenization
    #     sentences = sent_tokenize(text)

    #     # Calculate sentence similarity using TF-IDF and cosine similarity
    #     vectorizer = TfidfVectorizer()
    #     tfidf_matrix = vectorizer.fit_transform(sentences)
    #     similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)

    #     # Build graph using sentence similarity
    #     graph = DiGraph()
    #     for i in range(len(sentences)):
    #         for j in range(i+1, len(sentences)):
    #             graph.add_edge(i, j, weight=similarity_matrix[i, j])

    #     # Calculate sentence scores using TextRank
    #     scores = {}
    #     for node in graph.nodes():
    #         scores[node] = 0
    #         for neighbor in graph.neighbors(node):
    #             scores[node] += graph[node][neighbor]['weight']
    #     for node in scores:
    #         neighbors = list(graph.neighbors(node))
    #         degree = len(neighbors) or 1  # default to 1 if degree is zero
    #         scores[node] /= degree

    #     # Select top-scoring sentences for summary
    #     summary_sentences = sorted(scores, key=scores.get, reverse=True)

    #     # Create summary
    #     summary = ' '.join([sentences[i] for i in summary_sentences])

    #     return summary



def is_pdf_url(url: str) -> bool:
    """
    Returns True if the URL points to a PDF, False otherwise.
    """
    try:
        # 1. Check if the URL has a .pdf extension
        parsed_url = urllib.parse.urlparse(url)
        if parsed_url.path.endswith('.pdf'):
            return True

        # 2. Send a HEAD request to the URL to get the Content-Type header
        response = requests.head(url, allow_redirects=True, timeout=5)

        # 3. Check if the Content-Type header is application/pdf
        content_type = response.headers.get('Content-Type')
        if content_type and content_type.startswith('application/pdf'):
            return True

        # 4. Check if the URL returns a PDF MIME type
        mime_type, _ = mimetypes.guess_type(url)
        if mime_type and mime_type.startswith('application/pdf'):
            return True

        # 5. If all else fails, try to download a small chunk of the file and check its magic number
        response = requests.get(url, stream=True, timeout=5)
        chunk = response.raw.read(1024)
        if chunk.startswith(b'%PDF-'):
            return True

        # If none of the above checks pass, it's likely not a PDF
        return False

    except requests.exceptions.RequestException as e:
        # Handle requests exceptions (e.g. connection errors, timeouts)
        print(f"Error checking URL: {e}")
        return False

    except Exception as e:
        # Handle any other unexpected exceptions
        print(f"Error checking URL: {e}")
        return False



    def compress_content(self, content, llm , task_instance, max_tokens):
        """
        Compress the given content using the provided compression chain.
        The content is split into chunks with an overlap of 100 characters, and each chunk is compressed.
        The compressed chunks are then combined, and the process is repeated if the total token count is still greater than the max_tokens.

        Args:
            content (str): The content to be compressed.
            compression_chain: The chain to use for compressing the content.
            max_tokens (int): The maximum number of tokens allowed for the compressed content.

        Returns:
            str: The compressed content.
        """
        tokenizer = tiktoken.get_encoding("gpt2")
        
        chunk_size = max_tokens*3
        overlap = round(chunk_size*.1)

        compressed_content = ""

        compress_prompt = ChatPromptTemplate.from_messages([
            ("system",
            """
            <INSTRUCTION>
            Process the text in the following guidelines, no preamble or postamble:
            <GUIDELINES>
            - preserve all details
            - use markdown
            - do not summarize
            - remove redundancies, fluff, filler content, advertisements, sponsors, and other distracting elements    
            </GUIDELINES>
            """),
            ("human", "<TEXT>{query}</TEXT>"),
        ])

        text_splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)

        chunks = text_splitter.split_text(content)
        compress_chain = compress_prompt | llm | StrOutputParser()
        i=0
        chunks = [content[i:i+chunk_size] for i in range(0, len(content), chunk_size-overlap)]
        continue_compression = True
        last_chunk_size=len(chunks)
        while continue_compression:
            i+=1
            compressed_chunks = []
            last_token_size=0
            num_chunks = len(chunks)
            last_chunk_size=num_chunks
            print(f"Compressing iteration {i} with {num_chunks} chunks...")
            j=0
            task_instance.update_state(
                state='start compressing',
                meta={'current_chunk': j, 'total_chunks': num_chunks}
            )
            for chunk in chunks:
                j+=1
                print(f"Compressing chunk {j} of {num_chunks}...")
                compressed_chunk = compress_chain.invoke({'query': chunk})
                compressed_chunks.append(compressed_chunk)
                self.llm_tokens_sent += len(self.encoder.encode(compress_prompt.format(query=chunk), disallowed_special=()))
                self.llm_tokens_r += len(self.encoder.encode(compressed_chunk))
                print (f"LLM tokens received: {len(self.encoder.encode(compressed_chunk))}")
                # Send progress update
                task_instance.update_state(
                    state='compressing',
                    meta={'current_chunk': j, 'total_chunks': num_chunks}
                )

            compressed_content = "\n".join(compressed_chunks)
            print(compressed_content)
            compressed_tokens = tokenizer.encode(compressed_content, disallowed_special=())
            compressed_token_count = len(compressed_tokens)
            print(f"The compressed content has {compressed_token_count} tokens.")

            if compressed_token_count <= max_tokens:
                continue_compression = False
            else:
                chunks = text_splitter.split_text(compressed_content)
                print(f"Splitting into {len(chunks)} chunks. Last chunk size: {last_chunk_size}")
                if len(chunks) >= last_chunk_size: # if compression isn't getting much smaller then stop
                    continue_compression= False 

        return compressed_content

    def summarize(self, query, user, task_instance, base_url="http://192.168.30.100:11434"):
        """
        Generate a response to a user's query using the ChatOllama model.

        Args:
            query (str): The user's query (text or URL).
            base_url (str, optional): The base URL for the API endpoint. Defaults to "https://api.example.com/v1/chat".

        Returns:
            str: The response to the user's query, formatted in Markdown.
        """
        
        max_tokens=8192

        start_time = timezone.now()
        model = 'wizardlm2:7b-q8_0' # very very good
        #model = 'qwen:1.8b'        # bad
        #model = 'phi:latest'        # bad
        #model = 'openhermes:latest' # bad
        #model = 'mistral:7b-instruct-v0.2-q6_K' # ok
        #model = 'nous-hermes2-mixtral:8x7b-dpo-q4_K_M' # good
        #model = 'gemma:7b-instruct-v1.1-q8_0'  # worth investigating more, but not bad
        #model = 'adrienbrault/nous-hermes2pro:Q8_0' # not good
        #model = 'command-r:latest'
        #model = 'eramax/senku:latest' # bad
        #model = 'yi:6b-200k-fp16' # not enough vram
        #model = 'yi:6b-chat-fp16' # only outputted chinese -> didn't pursue
        #model = 'qwen:32b' # not great
        #model = 'dolphin-llama3:8b-v2.9-q8_0'
        #model = 'phi3:3.8b-mini-instruct-4k-fp16' # not that good
        #model = 'llama3:8b-instruct-fp16' # broken
        #model = 'dolphin-llama3:latest' # not that good
        #model = 'mixtral:8x7b-instruct-v0.1-q4_K_M'
        #model = 'herald/phi3-128k'


        # Initialize the ChatOllama model with the base_url parameter
        llm = ChatOllama(model=model, base_url=base_url, temperature=0.4, num_ctx=max_tokens)
        #    llm = ChatOllama(model="llama3:latest", base_url=base_url, num_ctx="8000",)

        # Define the prompt templates
        summarize_prompt = ChatPromptTemplate.from_messages([
            ("system",
            """
            <INSTRUCTION>
            Process the text in the following guidelines, no preamble or postamble:
            <GUIDELINES>
            - preserve all details
            - use markdown
            - do not summarize
            - remove redundancies, fluff, filler content, advertisements, sponsors, and other distracting elements    
            </GUIDELINES>
            </INSTRUCTION>
            """),
            ("human", """<TEXT>{query}\n</TEXT>
            <EXPECTED OUTPUT>
            "##### Title: create a pithy and insightful title\n
            ##### Date: provide the date if cited in source material, else 'not indicated'\n
            ##### Author(s): list the author(s) of the content(if available), else 'not indicated'\n
            ###### TLDR: write a concise, pithy summary of the content and it's conclusions\n\n

            """),
        ])

        summarize_chain = summarize_prompt | llm | StrOutputParser()

        # Check if the input is a URL
        url_pattern = r'^https?://\S+$'
        if re.match(url_pattern, query):
            # Scrape the website content
            youtube_regex = r"(?:https?:\/\/)?(?:www\.)?youtu(?:\.be|be\.com)\/(?:watch\?v=)?([\w-]{11})"
            match = re.match(youtube_regex, query)
            if match:
                # Use langchain YoutubeLoader to get the transcription
                loader = YoutubeLoader.from_youtube_url(query)
                docs = loader.load()

                content = ""
                for doc in docs:
                    content += doc.page_content + "\n"  # Combine page contents

            else: 
                if self.is_pdf_url(query):
                    pdfloader = PDFDocumentLoad()
                    docs = pdfloader.load_from_url(query)
                    content = ""
                    for doc in docs:
                        content += doc.page_content + "\n"  # Combine page contents
                else:
                    # assume it's text
                    browser_tools = BrowserTools()
                    content = browser_tools.scrape_website(query)

            #print("scraped content: ", content)
        else:
            # Summarize the provided text
            content = query

        tokenizer = tiktoken.get_encoding("gpt2")
        print(f"The content precompression has {len(tokenizer.encode(content,disallowed_special=()))} tokens.")
        cleaned_content=""
        cleaned_content = self.summarize_nlp(content)
        if cleaned_content:
            content = cleaned_content
        #print(f"cleaned content: {content}")
#        print(f"The content is:\n{content}")
        # Count the tokens in the content using tiktoken
        tokens = tokenizer.encode(content, disallowed_special=())
        token_count = len(tokens)

        print(f"The content now has {len(tokenizer.encode(content,disallowed_special=()))} tokens.")

        # Compress the content if it's greater than max tokens
        if token_count > max_tokens:
            compressed_content = self.compress_content(content, llm, task_instance, max_tokens)

            token_count = len(tokenizer.encode(compressed_content,disallowed_special=()))
            print(f"The compressed_content has {token_count} tokens.")
            # Update state to indicate summarization
            content=compressed_content

        task_instance.update_state(
            state='summarizing',
            meta={'current_chunk': 1,  'total_chunks': 1}
        )

        response = summarize_chain.invoke({'query': content})

        result = response

        end_time = timezone.now()
        duration = end_time - start_time
        
        #save the usage data to the database
        usage = SummarizerUsage.objects.create(
            user=user,
            query=query,
            response=result,
            duration = duration,
            content_token_size=token_count,
            content_character_count=len(content),
            total_input_tokens=self.llm_tokens_sent,
            total_output_tokens=self.llm_tokens_r,
            model_used = model
        )
        usage.save()
        return result

    #     prompt = ChatPromptTemplate.from_messages([
    #     ("system", 
    #     """# MISSION
    # You are a Sparse Priming Representation (SPR) writer. An SPR is a particular kind of use of language for advanced NLP, NLU, and NLG tasks. You will be given information by the USER which you are to render as an SPR.

    # # THEORY
    # LLMs are a kind of deep neural network. They have been demonstrated to embed knowledge, abilities, and concepts, ranging from reasoning to planning, and even to theory of mind. These are called latent abilities and latent content, collectively referred to as latent space. The latent space of an LLM can be activated with the correct series of words as inputs, which will create a useful internal state of the neural network. This is not unlike how the right shorthand cues can prime a human mind to think in a certain way. Like human minds, LLMs are associative, meaning you only need to use the correct associations to "prime" another model to think in the same way.

    # # METHODOLOGY
    # Render the conversation as a distilled list of succinct statements, assertions, associations, concepts, analogies, and metaphors. The idea is to capture as much, conceptually, as possible but with as few words as possible. Write it in a way that makes sense to you. Use complete sentences."""
    #     ),

================
File: apps/common/tests.py
================
from django.test import TestCase

# Create your tests here.

================
File: apps/common/utils.py
================
import requests
import mimetypes
import urllib.parse
import re
from django.core.cache import cache
import logging
import tiktoken
from django.conf import settings
from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatLiteLLM
from langchain.callbacks.base import BaseCallbackHandler
from langchain.callbacks.manager import CallbackManager



class TokenCounterCallback(BaseCallbackHandler):
    def __init__(self, tokenizer):
        self.llm = None
        self.input_tokens = 0
        self.output_tokens = 0
        self.tokenizer = tokenizer

    def on_llm_start(self, serialized, prompts, **kwargs):
        for prompt in prompts:
            self.input_tokens += len(self.tokenizer.encode(prompt, disallowed_special=()))

    def on_llm_end(self, response, **kwargs):
        for generation in response.generations:
            for result in generation:
                self.output_tokens += len(self.tokenizer.encode(result.text, disallowed_special=()))

def get_models():
    data=""
    #data = cache.get('models')
    if not data:
        url = f'{settings.API_BASE_URL}/models'
        headers = {'accept': 'application/json', 'Authorization': f'Bearer {settings.LITELLM_MASTER_KEY}'}
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            data = response.json()['data']
            # Sort the data by 'id' in ascending order
            data.sort(key=lambda x: x['id'])
            cache.set('models', data, 60*60)  # Cache data for 1 hour
        else:
            return None
    return [item['id'] for item in data]

def get_llm(model_name:str, temperature=0.0):

    tokenizer=tiktoken.get_encoding("cl100k_base")
    token_counter_callback = TokenCounterCallback(tokenizer)
     
    callback_manager = CallbackManager([token_counter_callback])  

    llm = ChatOpenAI(model=model_name, base_url=settings.OPENAI_API_BASE, api_key=settings.LITELLM_MASTER_KEY, temperature=temperature, callbacks=callback_manager)

    token_counter_callback.llm = llm
    return llm, token_counter_callback

    
def is_pdf_url(url: str) -> bool:
    """Determine if the given URL points to a PDF document."""
    try:
        parsed_url = urllib.parse.urlparse(url)
        if parsed_url.path.endswith('.pdf'):
            return True
        response = requests.head(url, allow_redirects=True, timeout=5)
        content_type = response.headers.get('Content-Type')
        if content_type and content_type.startswith('application/pdf'):
            return True
        mime_type, _ = mimetypes.guess_type(url)
        if mime_type and mime_type.startswith('application/pdf'):
            return True
        response = requests.get(url, stream=True, timeout=5)
        return response.raw.read(1024).startswith(b'%PDF-')
    except requests.exceptions.RequestException:
        return False

def is_youtube(url: str) -> bool:
    youtube_regex = r"(?:https?:\/\/)?(?:www\.)?youtu(?:\.be|be\.com)\/(?:watch\?v=)?([\w-]{11})"
    return re.match(youtube_regex, url)

def is_stock_symbol(query):
    url = f'https://www.alphavantage.co/query?function=SYMBOL_SEARCH&keywords={query}&apikey={settings.ALPHA_VANTAGE_API_KEY}'
    r=requests.get(url)
    data = r.json()
    print(data)
    if 'bestMatches' in data and len(data['bestMatches']) > 0:
        return True
    else:
        return False

def tokenize(text: str, tokenizer = "cl100k_base") -> int:
    """ Helper function to tokenize text and return token count """
    #logging.info(f'tokenize text: {text[:50]}...')
    return len(tokenizer.encode(text, disallowed_special=()))

def extract_top_level_domain(url):
  """Extracts only the top-level domain (TLD) from a URL, handling various cases.

  Args:
    url: The URL to extract the TLD from.

  Returns:
    The top-level domain (TLD) as a string (without protocol or subdomains), 
    or None if the TLD cannot be determined or if None is passed in.
  """
  if url is None:
    return None  # Handle None input explicitly

  try:
    # Remove protocol (http://, https://)
    url = url.split("//")[-1]  
    # Remove trailing slash
    url = url.rstrip("/")
    # Split into parts and extract TLD using the previous logic
    url_parts = url.split(".")
    if len(url_parts) > 1 and url_parts[-1] in {"com", "org", "net", "edu", "gov", "mil"}:
      return url_parts[-2]  # Return TLD (e.g., sld.com, sld.org)
    elif len(url_parts) > 2 and url_parts[-3] in {"co", "ac"}:
      return ".".join(url_parts[-2:])  # Handle "sld.co.uk", etc.
    else:
      return url_parts[-1]  # Default to last part 
  except IndexError:
    return None 

def normalize_url(url):
    """Normalize a single URL"""
    url = url.lower()
    parsed_url = urllib.parse.urlparse(url)
    if parsed_url.port == 80 and parsed_url.scheme == 'http':
        parsed_url = parsed_url._replace(netloc=parsed_url.netloc.split(':')[0])
    url = urllib.parse.urlunparse(parsed_url)
    url = url.rstrip('/')
    url = urllib.parse.urldefrag(url)[0]
    url = urllib.parse.unquote(url)
    return url

def compare_urls(url1, url2):
    """Compare two URLs after normalizing them"""
    url1 = normalize_url(url1)
    url2 = normalize_url(url2)
    return url1 == url2

================
File: apps/common/views.py
================
from django.shortcuts import render

# Create your views here.

================
File: apps/seo_manager/admin.py
================
from django.contrib import admin
from .models import ClientGroup, Client, SEOData, AIProvider

@admin.register(ClientGroup)
class ClientGroupAdmin(admin.ModelAdmin):
    list_display = ('name', 'parent')
    search_fields = ('name',)

@admin.register(Client)
class ClientAdmin(admin.ModelAdmin):
    list_display = ('name', 'website_url', 'status', 'group')
    list_filter = ('status', 'group')
    search_fields = ('name', 'website_url')

@admin.register(SEOData)
class SEODataAdmin(admin.ModelAdmin):
    list_display = ('client', 'date', 'traffic', 'keywords')
    list_filter = ('client', 'date')
    date_hierarchy = 'date'

@admin.register(AIProvider)
class AIProviderAdmin(admin.ModelAdmin):
    list_display = ('name', 'model', 'is_active')
    list_filter = ('is_active',)
    search_fields = ('name', 'model')

================
File: apps/seo_manager/apps.py
================
from django.apps import AppConfig

class SeoManagerConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'apps.seo_manager'

================
File: apps/seo_manager/forms.py
================
from django import forms
from .models import Client

class ClientForm(forms.ModelForm):
    class Meta:
        model = Client
        fields = ['name', 'website_url', 'status', 'group']
        widgets = {
            'name': forms.TextInput(attrs={'class': 'form-control'}),
            'website_url': forms.URLInput(attrs={'class': 'form-control'}),
            'status': forms.Select(attrs={'class': 'form-control'}),
            'group': forms.Select(attrs={'class': 'form-control'}),
        }

================
File: apps/seo_manager/google_analytics_service.py
================
import logging
from google.oauth2.credentials import Credentials
from google.oauth2 import service_account
from googleapiclient.discovery import build
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import DateRange, Metric, Dimension, RunReportRequest
import json

logger = logging.getLogger(__name__)

def get_analytics_service(credentials):
    try:
        if credentials.use_service_account:
            logger.info(f"Using service account for client {credentials.client.id}")
            service_account_info = json.loads(credentials.service_account_json)
            creds = service_account.Credentials.from_service_account_info(
                service_account_info,
                scopes=credentials.scopes if credentials.scopes else ['https://www.googleapis.com/auth/analytics.readonly']
            )
        else:
            logger.info(f"Using OAuth credentials for client {credentials.client.id}")
            creds = Credentials(
                token=credentials.access_token,
                refresh_token=credentials.refresh_token,
                token_uri=credentials.token_uri,
                client_id=credentials.ga_client_id,
                client_secret=credentials.client_secret,
                scopes=credentials.scopes if credentials.scopes else ['https://www.googleapis.com/auth/analytics.readonly']
            )
        return BetaAnalyticsDataClient(credentials=creds)
    except Exception as e:
        logger.error(f"Error creating analytics service: {str(e)}")
        raise
        
def get_analytics_data(client, property_id, start_date, end_date):
    request = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date=start_date, end_date=end_date)],
        metrics=[Metric(name="activeUsers"), Metric(name="screenPageViews")],
        dimensions=[Dimension(name="date"), Dimension(name="sourceMedium")]
    )
    
    response = client.run_report(request)
    return response
    
def process_analytics_data(response):
    processed_data = []
    for row in response.rows:
        processed_data.append({
            'date': row.dimension_values[0].value,
            'active_users': row.metric_values[0].value,
            'page_views': row.metric_values[1].value
        })
    return processed_data

def get_analytics_accounts(service_account_json):
    try:
        credentials = service_account.Credentials.from_service_account_info(
            json.loads(service_account_json),
            scopes=['https://www.googleapis.com/auth/analytics.readonly']
        )
        analytics = build('analyticsadmin', 'v1alpha', credentials=credentials)
        
        accounts = []
        account_summaries = analytics.accountSummaries().list().execute()
        
        for account_summary in account_summaries.get('accountSummaries', []):
            account_id = account_summary['account']
            account_name = account_summary['displayName']
            
            for property_summary in account_summary.get('propertySummaries', []):
                property_id = property_summary['property']
                property_name = property_summary['displayName']
                
                accounts.append({
                    'account_id': account_id,
                    'account_name': account_name,
                    'property_id': property_id,
                    'property_name': property_name,
                })
        
        logger.info(f"Retrieved {len(accounts)} accounts")
        return accounts
    except Exception as e:
        logger.error(f"Error in get_analytics_accounts: {str(e)}")
        raise

def get_analytics_accounts_oauth(credentials):
    try:
        analytics = build('analyticsadmin', 'v1alpha', credentials=credentials)
        
        accounts = []
        account_summaries = analytics.accountSummaries().list().execute()
        
        for account_summary in account_summaries.get('accountSummaries', []):
            account_id = account_summary['account']
            account_name = account_summary['displayName']
            
            for property_summary in account_summary.get('propertySummaries', []):
                property_id = property_summary['property']
                property_name = property_summary['displayName']
                
                accounts.append({
                    'account_id': account_id,
                    'account_name': account_name,
                    'property_id': property_id,
                    'property_name': property_name,
                })
        
        logger.info(f"Retrieved {len(accounts)} accounts via OAuth")
        return accounts
    except Exception as e:
        logger.error(f"Error in get_analytics_accounts_oauth: {str(e)}")
        raise

================
File: apps/seo_manager/google_auth.py
================
from google_auth_oauthlib.flow import Flow
from django.conf import settings
from django.urls import reverse
from google.oauth2.credentials import Credentials
from google.oauth2 import service_account
from googleapiclient.discovery import build
import json

def get_google_auth_flow(request):
    flow = Flow.from_client_secrets_file(
        settings.GOOGLE_CLIENT_SECRETS_FILE,
        scopes=['https://www.googleapis.com/auth/analytics.readonly',
                'https://www.googleapis.com/auth/webmasters.readonly'],
        redirect_uri=request.build_absolute_uri('/google/login/callback/')
    )
    return flow

def get_analytics_accounts_oauth(credentials):
    analytics = build('analyticsadmin', 'v1alpha', credentials=credentials)
    return fetch_analytics_accounts(analytics)

def get_analytics_accounts_service_account(service_account_json):
    credentials = service_account.Credentials.from_service_account_info(
        json.loads(service_account_json),
        scopes=['https://www.googleapis.com/auth/analytics.readonly']
    )
    analytics = build('analyticsadmin', 'v1alpha', credentials=credentials)
    return fetch_analytics_accounts(analytics)

def fetch_analytics_accounts(analytics):
    accounts = []
    account_summaries = analytics.accountSummaries().list().execute()
    
    for account_summary in account_summaries.get('accountSummaries', []):
        account_id = account_summary['account']
        account_name = account_summary['displayName']
        
        for property_summary in account_summary.get('propertySummaries', []):
            property_id = property_summary['property']
            property_name = property_summary['displayName']
            
            accounts.append({
                'account_id': account_id,
                'account_name': account_name,
                'property_id': property_id,
                'property_name': property_name,
            })
    
    return accounts

def get_search_console_service(credentials):
    return build('searchconsole', 'v1', credentials=credentials)

def get_search_console_properties(credentials):
    service = get_search_console_service(credentials)
    sites = service.sites().list().execute()
    return [site['siteUrl'] for site in sites.get('siteEntry', [])]

================
File: apps/seo_manager/models.py
================
from django.db import models
from django.contrib.auth.models import User
from django.utils import timezone

class ClientGroup(models.Model):
    name = models.CharField(max_length=100)
    parent = models.ForeignKey('self', on_delete=models.SET_NULL, null=True, blank=True, related_name='children')

    def __str__(self):
        return self.name

class Client(models.Model):
    STATUS_CHOICES = [
        ('active', 'Active'),
        ('inactive', 'Inactive'),
        ('on_hold', 'On Hold'),
    ]

    name = models.CharField(max_length=100)
    website_url = models.URLField()
    status = models.CharField(max_length=10, choices=STATUS_CHOICES, default='active')
    group = models.ForeignKey(ClientGroup, on_delete=models.SET_NULL, null=True, blank=True, related_name='clients')
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    def __str__(self):
        return self.name

class SEOData(models.Model):
    client = models.ForeignKey(Client, on_delete=models.CASCADE, related_name='seo_data')
    date = models.DateField()
    traffic = models.IntegerField()
    keywords = models.IntegerField()
    rankings = models.JSONField()  # Store rankings as JSON

    class Meta:
        unique_together = ['client', 'date']

class AIProvider(models.Model):
    name = models.CharField(max_length=100)
    api_key = models.CharField(max_length=255)
    model = models.CharField(max_length=100)
    parameters = models.JSONField(default=dict)
    is_active = models.BooleanField(default=True)

    def __str__(self):
        return self.name

class GoogleAnalyticsCredentials(models.Model):
    client = models.OneToOneField(Client, on_delete=models.CASCADE, related_name='ga_credentials')
    view_id = models.CharField(max_length=100, blank=True, null=True)  # Allow null values
    access_token = models.TextField(blank=True, null=True)  # Allow null for service accounts
    refresh_token = models.TextField(blank=True, null=True)  # Allow null for service accounts
    token_uri = models.URLField(blank=True, null=True)  # Allow null for service accounts
    ga_client_id = models.CharField(max_length=100, blank=True, null=True)  # Allow null for service accounts
    client_secret = models.CharField(max_length=100, blank=True, null=True)  # Allow null for service accounts
    use_service_account = models.BooleanField(default=False)
    service_account_json = models.TextField(blank=True, null=True)
    user_email = models.EmailField()  # Add this field if it doesn't exist
    # Add the scopes attribute with a default value
    scopes = models.JSONField(default=list)

    def __str__(self):
        return f"GA Credentials for {self.client.name}"
# Add this new model
class SearchConsoleCredentials(models.Model):
    client = models.OneToOneField(Client, on_delete=models.CASCADE, related_name='sc_credentials')
    property_url = models.URLField()
    access_token = models.TextField(blank=True, null=True)
    refresh_token = models.TextField(blank=True, null=True)
    token_uri = models.URLField(blank=True, null=True)
    sc_client_id = models.CharField(max_length=100, blank=True, null=True)  # Renamed from client_id
    client_secret = models.CharField(max_length=100, blank=True, null=True)

    def __str__(self):
        return f"Search Console Credentials for {self.client.name}"

class SummarizerUsage(models.Model):
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    query = models.TextField()
    compressed_content = models.TextField()
    response = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)
    duration = models.DurationField()
    content_token_size = models.IntegerField()
    content_character_count = models.IntegerField()
    total_input_tokens = models.IntegerField()
    total_output_tokens = models.IntegerField()
    model_used = models.CharField(max_length=100)

================
File: apps/seo_manager/services.py
================
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from google.auth.exceptions import RefreshError
from google.auth.transport.requests import Request  # Add this import
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import (
  DateRange,
  Dimension,
  Metric,
  RunReportRequest,
)

def get_analytics_service(ga_credentials, request):
  print("Entering get_analytics_service")
  try:
      print("GA Credentials:", ga_credentials)
      print("User Email:", ga_credentials.user_email)
      credentials = Credentials(
          token=ga_credentials.access_token,
          refresh_token=ga_credentials.refresh_token,
          token_uri=ga_credentials.token_uri,
          client_id=ga_credentials.ga_client_id,
          client_secret=ga_credentials.client_secret,
          scopes=ga_credentials.scopes
      )
      print("Credentials created, refreshing...")
      credentials.refresh(Request())
      print("Credentials refreshed successfully.")
      client = BetaAnalyticsDataClient(credentials=credentials)
      print("Analytics client created successfully, client:", client)
      return client
  except RefreshError as e:
      print(f"Error refreshing credentials: {e}")
      raise e
  finally:
      print("Exiting get_analytics_service")

def get_analytics_data(client, property_id, start_date, end_date):
  print("Entering get_analytics_data")
  print(f"Fetching analytics data for Property ID: {property_id}, Start Date: {start_date}, End Date: {end_date}")
  
  try:
      request = RunReportRequest(
          property=f"properties/{property_id}",
          dimensions=[Dimension(name="date")],
          metrics=[
              Metric(name="sessions"),
              Metric(name="screenPageViews")  # Changed from "pageviews" to "screenPageViews"
          ],
          date_ranges=[DateRange(start_date=start_date, end_date=end_date)],
      )
      response = client.run_report(request)
      print("Analytics data fetched successfully.")
      return response
  except Exception as e:
      print(f"Error fetching analytics data: {e}")
      raise e
  finally:
      print("Exiting get_analytics_data")

================
File: apps/seo_manager/urls.py
================
from django.urls import path, include
from . import views, views_summarizer

app_name = 'seo_manager'

urlpatterns = [
    path('', views.dashboard, name='dashboard'),
    path('summarize/', views_summarizer.summarize_view, name='summarize_view'),
    path('task_status/<str:task_id>/', views_summarizer.task_status, name='task_status'),
    path('clients/', include([
        path('', views.client_list, name='client_list'),
        path('<int:client_id>/', include([
            path('', views.client_detail, name='client_detail'),
            path('analytics/', views.client_analytics, name='client_analytics'),
            path('search-console/', views.client_search_console, name='client_search_console'),
            path('ads/', views.client_ads, name='client_ads'),
            path('dataforseo/', views.client_dataforseo, name='client_dataforseo'),
            path('credentials/', include([
                path('ga/oauth/add/', views.add_ga_credentials_oauth, name='add_ga_credentials_oauth'),
                path('ga/service-account/add/', views.add_ga_credentials_service_account, name='add_ga_credentials_service_account'),
                path('ga/remove/', views.remove_ga_credentials, name='remove_ga_credentials'),
                path('sc/add/', views.add_sc_credentials, name='add_sc_credentials'),
                path('sc/remove/', views.remove_sc_credentials, name='remove_sc_credentials'),
            ])),
        ])),
    ])),
    path('summarize/', views_summarizer.summarize_view, name='summarize_view'),
    path('test/', views.test_view, name='test_view'),
]

================
File: apps/seo_manager/views_summarizer.py
================
from django.http import HttpResponseRedirect, HttpResponse
from django.urls import reverse
from home.forms import RegistrationForm, LoginForm, UserPasswordResetForm, UserSetPasswordForm, UserPasswordChangeForm
from django.core import serializers
from django.contrib.auth.views import LoginView, PasswordResetView, PasswordChangeView, PasswordResetConfirmView
from django.contrib.auth import logout
from django.contrib.auth.mixins import LoginRequiredMixin, UserPassesTestMixin
from django.contrib.admin.views.decorators import staff_member_required
from django.contrib.auth.models import User
from django.conf import settings
from django.views.generic import TemplateView, ListView, CreateView, UpdateView, RedirectView, DeleteView, View
from django.views.generic.edit import FormView
from django.utils.decorators import method_decorator
from apps.tasks.tasks import summarize_content
import mistune
from django.utils.safestring import mark_safe
from django.http import JsonResponse
from celery.result import AsyncResult
import logging
from apps.common.utils import get_models

import json  # Add this import at the top of the file
from django.shortcuts import render, get_object_or_404, redirect
from django.contrib.auth.decorators import login_required
from django.contrib import messages
from .models import Client, SEOData, GoogleAnalyticsCredentials, SearchConsoleCredentials, SummarizerUsage
from .services import get_analytics_service, get_analytics_data
from .google_auth import get_google_auth_flow, get_analytics_accounts_oauth, get_analytics_accounts_service_account, get_search_console_properties
from datetime import datetime, timedelta
from django.http import HttpResponse
from google_auth_oauthlib.flow import Flow
from django.urls import reverse
from google.auth.exceptions import RefreshError
from googleapiclient.errors import HttpError  # Add this import


@login_required
def summarize_view(request):

  models = get_models()
  logging.info(f'request.user.id: {request.user.id}')
  model_selected = settings.SUMMARIZER
  #logging.info ("Model selected: " + model_selected)
  if request.method == 'POST':

    text_to_summarize = request.POST.get('query_text_value')
    model_selected = request.POST.get('model_selected_value')
    task = summarize_content.delay(text_to_summarize, request.user.id, model_selected)
    return JsonResponse({'task_id': task.id})
  
  user = User.objects.get(id=request.user.id)
  summarizations = SummarizerUsage .objects.filter(user=user).order_by('-created_at')
  
  for summ in summarizations:
    summ.html_result = mistune.html(summ.response + '\n\n---Detail---------\n\n'+summ.compressed_content)
    
  task_result = None
  task_status = None
  model_selected =  settings.SUMMARIZER
  context = {
    'task_result': task_result,
    'task_status': task_status,
    'summarizations': summarizations,
    'models': models,
    'model_selected': model_selected
  }
  return render(request, 'pages/apps/summarize.html', context)

def task_status(request, task_id):
    current_chunk = 0
    total_chunks = 1
    task_result = AsyncResult(task_id)
    # logging.info(f"task status:{task_result.status}")
    if task_result.info is not None:
      # logging.info(f"task info:{task_result.info}")
      if task_result.state == 'SUCCESS':
          result = task_result.result
          html_result = mistune.html(result)
          return JsonResponse({'status': 'SUCCESS', 'result': html_result})
      elif task_result.state == 'FAILURE':
          error = str(task_result.result)
          return JsonResponse({'status': 'FAILURE', 'result': error})
      elif task_result.status == 'processing':
          progress = task_result.info
          current_chunk = progress.get('current_chunk', 0)
          total_chunks = progress.get('total_chunks', 0)
          return JsonResponse({'status': task_result.status, 'current': current_chunk, 'total': total_chunks})
      else:
          if task_result.status:
              return JsonResponse({'status': task_result.status})
          else:
              return JsonResponse({'status': 'PENDING'})
    else:
        return JsonResponse({'status': 'PENDING'})

================
File: apps/seo_manager/views.py
================
import json  # Add this import at the top of the file
from django.shortcuts import render, get_object_or_404, redirect
from django.contrib.auth.decorators import login_required
from django.contrib import messages
from .models import Client, SEOData, GoogleAnalyticsCredentials, SearchConsoleCredentials
from .services import get_analytics_service, get_analytics_data
from .google_auth import get_google_auth_flow, get_analytics_accounts_oauth, get_analytics_accounts_service_account, get_search_console_properties
from datetime import datetime, timedelta
from django.http import HttpResponse
from google_auth_oauthlib.flow import Flow
from django.urls import reverse
from google.auth.exceptions import RefreshError
from googleapiclient.errors import HttpError  # Add this import

@login_required
def dashboard(request):
    total_clients = Client.objects.count()
    return render(request, 'seo_manager/dashboard.html', {'total_clients': total_clients})

def client_list(request):
    clients = Client.objects.all()
    return render(request, 'seo_manager/client_list.html', {'clients': clients})

@login_required
def client_detail(request, client_id):
    client = get_object_or_404(Client, id=client_id)
    seo_data = SEOData.objects.filter(client=client).order_by('-date')[:30]
    
    # Clear all credential-related session data
    credential_keys = ['accounts', 'properties', 'access_token', 'refresh_token', 'token_uri', 'client_id', 'client_secret', 'service_account_json']
    for key in credential_keys:
        request.session.pop(key, None)
    
    context = {
        'client': client,
        'seo_data': seo_data,
    }
    
    return render(request, 'seo_manager/client_detail.html', context)

@login_required
def client_analytics(request, client_id):
  client = get_object_or_404(Client, id=client_id)
  ga_credentials = get_object_or_404(GoogleAnalyticsCredentials, client=client)
  print("GA Credentials:", ga_credentials)
  try:
      analytics_client = get_analytics_service(ga_credentials, request)
      print("Analytics Client:", analytics_client)
      end_date = datetime.now().strftime('%Y-%m-%d')
      start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
      print("Start Date:", start_date, "End Date:", end_date)

      property_id = ga_credentials.view_id.replace('properties/', '')
      print("Property ID:", property_id)

      analytics_data = get_analytics_data(analytics_client, property_id, start_date, end_date)
      print("Analytics Data:", analytics_data)

      processed_data = process_analytics_data(analytics_data)
      print("Processed Data:", processed_data)

      # Convert processed_data to JSON for the template
      json_data = json.dumps(processed_data)
      
      return render(request, 'seo_manager/client_analytics.html', {
          'client': client,
          'analytics_data': json_data,
      })
  except Exception as e:
      print("Unexpected error:", str(e))
      messages.error(request, "An unexpected error occurred.")
      return redirect('seo_manager:client_detail', client_id=client.id)
        
def extract_source_data(analytics_data):
  source_data = []
  for row in analytics_data.rows:
      # Assuming the dimensions are ordered as [date, source/medium]
      # and metrics as [sessions, pageviews]
      source_medium = row.dimension_values[1].value
      sessions = int(row.metric_values[0].value)
      
      # Check if this source/medium already exists in our list
      existing_entry = next((item for item in source_data if item['source_medium'] == source_medium), None)
      
      if existing_entry:
          # If it exists, add to the sessions count
          existing_entry['sessions'] += sessions
      else:
          # If it doesn't exist, create a new entry
          source_data.append({
              'source_medium': source_medium,
              'sessions': sessions,
          })
  
  # Sort the data by sessions in descending order
  source_data.sort(key=lambda x: x['sessions'], reverse=True)
  
  return source_data

def process_analytics_data(response):
  processed_data = []
  for row in response.rows:
      date = row.dimension_values[0].value
      sessions = int(row.metric_values[0].value)
      page_views = int(row.metric_values[1].value)
      processed_data.append({
          'date': date,
          'sessions': sessions,
          'pageviews': page_views
      })
  return processed_data

@login_required
def client_search_console(request, client_id):
    client = get_object_or_404(Client, id=client_id)
    # Implement Google Search Console data fetching here
    return render(request, 'seo_manager/client_search_console.html', {'client': client})

@login_required
def client_ads(request, client_id):
    client = get_object_or_404(Client, id=client_id)
    # Implement Google Ads data fetching here
    return render(request, 'seo_manager/client_ads.html', {'client': client})

@login_required
def client_dataforseo(request, client_id):
    client = get_object_or_404(Client, id=client_id)
    # Implement DataForSEO data fetching here
    return render(request, 'seo_manager/client_dataforseo.html', {'client': client})

def test_view(request):
    return HttpResponse("This is a test view.")

@login_required
def add_ga_credentials_oauth(request, client_id):
    client = get_object_or_404(Client, id=client_id)
    
    if request.method == 'POST':
        selected_account = request.POST.get('selected_account')
        if selected_account:
            accounts = request.session.get('accounts', [])
            account_data = next((account for account in accounts if account['property_id'] == selected_account), None)
            if account_data:
                GoogleAnalyticsCredentials.objects.update_or_create(
                    client=client,
                    defaults={
                        'access_token': request.session.get('access_token', ''),
                        'refresh_token': request.session.get('refresh_token', ''),
                        'token_uri': request.session.get('token_uri', ''),
                        'ga_client_id': request.session.get('client_id', ''),
                        'client_secret': request.session.get('client_secret', ''),
                        'use_service_account': False,
                        'view_id': account_data['property_id'],
                    }
                )
                messages.success(request, "Google Analytics credentials (OAuth) added successfully.")
                return redirect('seo_manager:client_detail', client_id=client.id)
            else:
                messages.error(request, "Selected account not found. Please try again.")
        else:
            messages.error(request, "Please select an account.")
    
    if 'accounts' in request.session:
        return render(request, 'seo_manager/select_analytics_account.html', {
            'client': client,
            'accounts': request.session['accounts'],
        })
    
    flow = get_google_auth_flow(request)
    authorization_url, state = flow.authorization_url(
        access_type='offline',
        include_granted_scopes='true',
        state=f"{client_id}_ga",
        prompt='consent'
    )
    request.session['oauth_state'] = state
    return redirect(authorization_url)

@login_required
def add_ga_credentials_service_account(request, client_id):
    client = get_object_or_404(Client, id=client_id)
    
    if request.method == 'POST':
        if 'selected_account' in request.POST:
            selected_account = request.POST.get('selected_account')
            if selected_account:
                accounts = request.session.get('accounts', [])
                account_data = next((account for account in accounts if account['property_id'] == selected_account), None)
                if account_data:
                    GoogleAnalyticsCredentials.objects.update_or_create(
                        client=client,
                        defaults={
                            'service_account_json': request.session.get('service_account_json', ''),
                            'use_service_account': True,
                            'view_id': account_data['property_id'],
                        }
                    )
                    messages.success(request, "Google Analytics credentials (Service Account) added successfully.")
                    return redirect('seo_manager:client_detail', client_id=client.id)
                else:
                    messages.error(request, "Selected account not found. Please try again.")
            else:
                messages.error(request, "Please select an account.")
        elif 'service_account_file' in request.FILES:
            service_account_file = request.FILES['service_account_file']
            try:
                service_account_info = json.load(service_account_file)
                service_account_json = json.dumps(service_account_info)
                accounts = get_analytics_accounts_service_account(service_account_json)
                request.session['accounts'] = accounts
                request.session['service_account_json'] = service_account_json
                return render(request, 'seo_manager/select_analytics_account.html', {
                    'client': client,
                    'accounts': accounts,
                })
            except json.JSONDecodeError:
                messages.error(request, "Invalid JSON file. Please upload a valid service account JSON file.")
        else:
            messages.error(request, "No file uploaded. Please select a service account JSON file.")
    
    if 'accounts' in request.session:
        return render(request, 'seo_manager/select_analytics_account.html', {
            'client': client,
            'accounts': request.session['accounts'],
        })
    
    return render(request, 'seo_manager/add_ga_credentials_service_account.html', {'client': client})

@login_required
def google_oauth_callback(request):
    state = request.GET.get('state')
    stored_state = request.session.pop('oauth_state', None)
    
    if state != stored_state:
        messages.error(request, "Invalid state parameter. Please try again.")
        return redirect('seo_manager:client_list')
    
    client_id, credential_type = state.split('_')
    client = get_object_or_404(Client, id=client_id)
    
    flow = get_google_auth_flow(request)
    flow.fetch_token(code=request.GET.get('code'))
    
    credentials = flow.credentials
    
    if credential_type == 'ga':
        accounts = get_analytics_accounts_oauth(credentials)
        request.session['accounts'] = accounts
        request.session['access_token'] = credentials.token
        request.session['refresh_token'] = credentials.refresh_token
        request.session['token_uri'] = credentials.token_uri
        request.session['client_id'] = credentials.client_id
        request.session['client_secret'] = credentials.client_secret
        return redirect('seo_manager:add_ga_credentials_oauth', client_id=client_id)
    elif credential_type == 'sc':
        properties = get_search_console_properties(credentials)
        request.session['properties'] = properties
        request.session['access_token'] = credentials.token
        request.session['refresh_token'] = credentials.refresh_token
        request.session['token_uri'] = credentials.token_uri
        request.session['client_id'] = credentials.client_id
        request.session['client_secret'] = credentials.client_secret
        return redirect('seo_manager:add_sc_credentials', client_id=client_id)
    else:
        messages.error(request, "Invalid credential type.")
        return redirect('seo_manager:client_detail', client_id=client_id)

@login_required
def remove_ga_credentials(request, client_id):
    client = get_object_or_404(Client, id=client_id)
    if client.ga_credentials:
        client.ga_credentials.delete()
        messages.success(request, "Google Analytics credentials removed successfully.")
    return redirect('seo_manager:client_detail', client_id=client.id)

@login_required
def add_sc_credentials(request, client_id):
    client = get_object_or_404(Client, id=client_id)
    
    if request.method == 'POST':
        selected_property = request.POST.get('selected_property')
        if selected_property:
            try:
                SearchConsoleCredentials.objects.update_or_create(
                    client=client,
                    defaults={
                        'property_url': selected_property,
                        'access_token': request.session.get('access_token', ''),
                        'refresh_token': request.session.get('refresh_token', ''),
                        'token_uri': request.session.get('token_uri', ''),
                        'sc_client_id': request.session.get('client_id', ''),
                        'client_secret': request.session.get('client_secret', ''),
                    }
                )
                messages.success(request, "Search Console credentials added successfully.")
                
                # Clear session data after successful addition
                for key in ['properties', 'access_token', 'refresh_token', 'token_uri', 'client_id', 'client_secret']:
                    request.session.pop(key, None)
                
                return redirect('seo_manager:client_detail', client_id=client.id)
            except Exception as e:
                messages.error(request, f"Error saving Search Console credentials: {str(e)}")
        else:
            messages.error(request, "Please select a property.")
    
    if 'properties' in request.session:
        return render(request, 'seo_manager/select_search_console_property.html', {
            'client': client,
            'properties': request.session['properties'],
        })
    
    # Check if credentials already exist
    if hasattr(client, 'sc_credentials'):
        messages.warning(request, "Search Console credentials already exist for this client. Remove them first to add new ones.")
        return redirect('seo_manager:client_detail', client_id=client.id)
    
    flow = get_google_auth_flow(request)
    authorization_url, state = flow.authorization_url(
        access_type='offline',
        include_granted_scopes='true',
        state=f"{client_id}_sc",
        prompt='consent'
    )
    request.session['oauth_state'] = state
    return redirect(authorization_url)

@login_required
def remove_sc_credentials(request, client_id):
    client = get_object_or_404(Client, id=client_id)
    try:
        if hasattr(client, 'sc_credentials'):
            client.sc_credentials.delete()
            messages.success(request, "Search Console credentials removed successfully.")
        else:
            messages.warning(request, "No Search Console credentials found for this client.")
    except Exception as e:
        messages.error(request, f"Error removing Search Console credentials: {str(e)}")
    
    # Clear session data related to SC credentials
    for key in ['properties', 'access_token', 'refresh_token', 'token_uri', 'client_id', 'client_secret']:
        request.session.pop(key, None)
    
    return redirect('seo_manager:client_detail', client_id=client.id)

================
File: core/asgi.py
================
"""
ASGI config for core project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/4.2/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings')

application = get_asgi_application()

================
File: core/settings.py
================
"""
Django settings for core project.

Generated by 'django-admin startproject' using Django 4.2.9.

For more information on this file, see
https://docs.djangoproject.com/en/4.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/4.2/ref/settings/
"""

from pathlib import Path
from django.utils.translation import gettext_lazy as _
from django.contrib import messages
from dotenv import load_dotenv
from str2bool       import str2bool 
import os, random, string, sys

load_dotenv()

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent

# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/4.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = os.environ.get('SECRET_KEY')
if not SECRET_KEY:
    SECRET_KEY = ''.join(random.choice( string.ascii_lowercase  ) for i in range( 32 ))

# Enable/Disable DEBUG Mode
DEBUG = str2bool(os.environ.get('DEBUG'))
#print(' DEBUG -> ' + str(DEBUG) ) 

ALLOWED_HOSTS = ['*']

# Used by DEBUG-Toolbar 
INTERNAL_IPS = [
    "127.0.0.1",
]

# Add here your deployment HOSTS
CSRF_TRUSTED_ORIGINS = ['http://localhost:8000', 'http://localhost:5085', 'http://127.0.0.1:8000', 'https://app.neuralami.com', 'http://127.0.0.1:5085', 'https://a36afd9c-6d6b-443f-af26-9f9eddab3ba1-00-12u9itbtcgrof.riker.replit.dev', 'https://manager.neuralami.com'] 


# Application definition

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',

    'home',
    'apps.api',
    'apps.charts',
    'apps.common',
    'apps.file_manager',
    'apps.tables',
    'apps.tasks',
    'apps.users',
    'apps.seo_manager',

    'allauth',
    'allauth.account',
    'allauth.socialaccount',
    'allauth.socialaccount.providers.google',
    'allauth.socialaccount.providers.github',

    'django_celery_results',
    'debug_toolbar',
    'django_quill',

    'rest_framework',
    'drf_spectacular',
    'django_api_gen',
]

SITE_ID = 1

MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    "whitenoise.middleware.WhiteNoiseMiddleware",
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.locale.LocaleMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',

    # Required for allauth
    'allauth.account.middleware.AccountMiddleware',
    # Required for debug toolbar
    'debug_toolbar.middleware.DebugToolbarMiddleware',
]

ROOT_URLCONF = 'core.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [
            BASE_DIR / 'templates',
        ],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'core.wsgi.application'


# Database
# https://docs.djangoproject.com/en/4.2/ref/settings/#databases

DB_ENGINE   = os.getenv('DB_ENGINE'   , None)
DB_USERNAME = os.getenv('DB_USERNAME' , None)
DB_PASS     = os.getenv('DB_PASS'     , None)
DB_HOST     = os.getenv('DB_HOST'     , None)
DB_PORT     = os.getenv('DB_PORT'     , None)
DB_NAME     = os.getenv('DB_NAME'     , None)

if DB_ENGINE and DB_NAME and DB_USERNAME:
    DATABASES = { 
      'default': {
        'ENGINE'  : 'django.db.backends.' + DB_ENGINE, 
        'NAME'    : DB_NAME,
        'USER'    : DB_USERNAME,
        'PASSWORD': DB_PASS,
        'HOST'    : DB_HOST,
        'PORT'    : DB_PORT,
        }, 
    }
else:
    DATABASES = {
        'default': {
            'ENGINE': 'django.db.backends.sqlite3',
            'NAME': 'db.sqlite3',
        }
    }

# Password validation
# https://docs.djangoproject.com/en/4.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/4.2/topics/i18n/

LANGUAGES = [
    ('en', _('English (US)')),
    ('de', _('Deutsch')),
    ('it', _('Italiano')),
]

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_TZ = True

LOCALE_PATHS = [
    os.path.join(BASE_DIR, 'locale'),
]

# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/4.2/howto/static-files/

STATIC_URL = 'static/'
STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')

STATICFILES_DIRS = [
    os.path.join(BASE_DIR,'static'),
]

MEDIA_URL = 'media/'
MEDIA_ROOT = os.path.join(BASE_DIR, 'media')

# Default primary key field type
# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'


LOGIN_REDIRECT_URL = '/'
LOGIN_URL = '/accounts/login/illustration-login/'

# AllAuth
ACCOUNT_EMAIL_VERIFICATION =  os.getenv('ACCOUNT_EMAIL_VERIFICATION', 'none')
ACCOUNT_EMAIL_REQUIRED = True
ACCOUNT_AUTHENTICATION_METHOD = 'email'
ACCOUNT_USERNAME_REQUIRED = False
ACCOUNT_CONFIRM_EMAIL_ON_GET = True
ACCOUNT_LOGIN_ON_EMAIL_CONFIRMATION = True
ACCOUNT_UNIQUE_EMAIL = True

AUTHENTICATION_BACKENDS = [
    'django.contrib.auth.backends.ModelBackend',
    'allauth.account.auth_backends.AuthenticationBackend',
]

SOCIALACCOUNT_PROVIDERS = {
    'google': {
        'APP':{
            'client_id': os.getenv('GOOGLE_CLIENT_ID', default=""),
            'secret': os.getenv('GOOGLE_SECRET_KEY', default=""),
        }
    },
    'github': {
        'APP':{
            'client_id': os.getenv('GITHUB_CLINET_ID', default=""),
            'secret': os.getenv('GITHUB_SECRET_KEY', default=""),
        }
    }
}

GOOGLE_CLIENT_SECRETS_FILE = os.getenv('GOOGLE_CLIENT_SECRETS_FILE', default="")

# ### Async Tasks (Celery) Settings ###

CELERY_SCRIPTS_DIR        = os.path.join(BASE_DIR, "tasks_scripts" )

CELERY_LOGS_URL           = "/tasks_logs/"
CELERY_LOGS_DIR           = os.path.join(BASE_DIR, "tasks_logs"    )

CELERY_BROKER_URL         = os.environ.get("CELERY_BROKER", "redis://redis:6379")
CELERY_RESULT_BACKEND     = os.environ.get("CELERY_BROKER", "redis://redis:6379")

CELERY_TASK_TRACK_STARTED = True
CELERY_TASK_TIME_LIMIT    = 30 * 60
CELERY_CACHE_BACKEND      = "django-cache"
CELERY_RESULT_BACKEND     = "django-db"
CELERY_RESULT_EXTENDED    = True
CELERY_RESULT_EXPIRES     = 60*60*24*30 # Results expire after 1 month
CELERY_ACCEPT_CONTENT     = ["json"]
CELERY_TASK_SERIALIZER    = 'json'
CELERY_RESULT_SERIALIZER  = 'json'
########################################

X_FRAME_OPTIONS = 'SAMEORIGIN'

# ### API-GENERATOR Settings ###
API_GENERATOR = {
    'sales'   : "apps.common.models.Sales",
}

REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework.authentication.TokenAuthentication',
        'rest_framework.authentication.SessionAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_SCHEMA_CLASS': 'drf_spectacular.openapi.AutoSchema',
}
########################################

MESSAGE_TAGS = {
    messages.DEBUG: 'alert-info',
    messages.INFO: 'alert-info',
    messages.SUCCESS: 'alert-success',
    messages.WARNING: 'alert-warning',
    messages.ERROR: 'alert-danger',
}

#SECURE_SSL_REDIRECT = True
#SESSION_COOKIE_SECURE = True
#CSRF_COOKIE_SECURE = True
ACCOUNT_DEFAULT_HTTP_PROTOCOL = 'https'


API_BASE_URL = os.environ.get('API_BASE_URL')
LITELLM_MASTER_KEY= os.environ.get('LITELLM_MASTER_KEY')
SERPAPI_API_KEY=os.environ.get('SERPAPI_API_KEY')
OPENAI_API_KEY=os.environ.get('OPENAI_API_KEY')
OPENAI_API_BASE=os.environ.get('OPENAI_API_BASE')
ANTHROPIC_API_KEY=os.environ.get('ANTHROPIC_API_KEY')
ALPHA_VANTAGE_API_KEY=os.environ.get('ALPHA_VANTAGE_API_KEY')
DATAFORSEO_EMAIL = os.environ.get('DATAFORSEO_EMAIL')
DATAFORSEO_PASSWORD = os.environ.get('DATAFORSEO_PASSWORD')

SONNET=os.environ.get('SONNET')
OPUS=os.environ.get('OPUS')
HAIKU=os.environ.get('HAIKU')
GENERAL_MODEL=os.environ.get('GENERAL_MODEL')
TEXT_MODEL=os.environ.get('TEXT_MODEL')
CODING_MODEL=os.environ.get('CODING_MODEL')
GROQMIXTRAL=os.environ.get('GROQMIXTRAL')
LOCAL_LONG=os.environ.get('LOCAL_LONG')
SUMMARIZER=os.environ.get('SUMMARIZER')
SUMMARIZER_MAX_TOKENS=int(os.environ.get('SUMMARIZER_MAX_TOKENS'))

MIXTRAL=os.environ.get('MIXTRAL')
MISTRAL=os.environ.get('MISTRAL')
PHI3=os.environ.get('PHI3')
QWEN32=os.environ.get('QWEN32')
QWEN14=os.environ.get('QWEN14')
QWEN2=os.environ.get('QWEN2_7b_8')
YI=os.environ.get('YI')

EMAIL_ADDRESS = os.environ.get('EMAIL_ADDRESS')
COMPANY_NAME = os.environ.get('COMPANY_NAME')


BROWSERLESS_API_KEY=os.environ.get('BROWSERLESS_API_KEY')
BROWSERLESS_BASE_URL=os.environ.get('BROWSERLESS_BASE_URL')
DOWNLOAD_FOLDER = os.environ.get('DOWNLOAD_FOLDER')

================
File: core/urls.py
================
"""
URL configuration for core project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/4.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path, include, re_path
from django.conf import settings
from django.conf.urls.static import static
from django.conf.urls.i18n import i18n_patterns
from home import views
from django.views.static import serve
from apps.seo_manager import views as seo_views  # Add this import

handler404 = 'home.views.error_404'
handler500 = 'home.views.error_500'

urlpatterns = [
    path('admin/', admin.site.urls),
    path('', include('home.urls')),
    path("api/", include("apps.api.urls")),
    path('charts/', include('apps.charts.urls')),
    path('tasks/', include('apps.tasks.urls')),
    path("tables/", include("apps.tables.urls")),
    path('', include('apps.file_manager.urls')),
    path("users/", include("apps.users.urls")),
    path('i18n/', include('django.conf.urls.i18n')),
    path('accounts/', include('allauth.urls')),

    re_path(r'^media/(?P<path>.*)$', serve,{'document_root': settings.MEDIA_ROOT}), 
    re_path(r'^static/(?P<path>.*)$', serve,{'document_root': settings.STATIC_ROOT}), 

    # Debug toolbar
    path("__debug__/", include("debug_toolbar.urls")),
] + static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)


urlpatterns += i18n_patterns(
    path('i18n/', views.i18n_view, name="i18n_view")
)

urlpatterns += [
    path('seo/', include('apps.seo_manager.urls')),
    # Add this line to handle the Google OAuth callback at the root level
    path('google/login/callback/', seo_views.google_oauth_callback, name='google_oauth_callback'),
]

================
File: core/wsgi.py
================
"""
WSGI config for core project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/4.2/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings')

application = get_wsgi_application()

================
File: home/templatetags/admin_soft.py
================
# -*- encoding: utf-8 -*-
"""
Copyright (c) 2019 - present AppSeed.us
"""
import re
from django import template
from django.utils.html import format_html
from home.utils import get_menu_items
from django.utils.safestring import mark_safe
from django.contrib.admin.views.main import (PAGE_VAR)

register = template.Library()
assignment_tag = register.assignment_tag if hasattr(register, 'assignment_tag') else register.simple_tag


@register.filter
def clean_text(value):
    res = value.replace('\n', ' ')
    return res


@register.filter
def checkbox(value):
    res = re.sub(r"</?(?i:td)(.|\n)*?>", "", value)
    return res


@assignment_tag(takes_context=True)
def admin_get_menu(context):
    return get_menu_items(context)


@assignment_tag(takes_context=True)
def get_direction(context):
    res = {
        'panel': 'text-left',
        'notify': 'right',
        'float': 'float-right',
        'reverse_panel': 'text-right',
        'nav': 'ml-auto'
    }

    if context.get('LANGUAGE_BIDI'):
        res['panel'] = 'text-right'
        res['notify'] = 'left'
        res['float'] = ''
        res['reverse_panel'] = 'text-left'
        res['nav'] = 'mr-auto'
    return res


@assignment_tag(takes_context=True)
def get_admin_setting(context):
    # user = context.get('request').user
    # admin_black_setting = user.admin_black_setting if hasattr(user, 'admin_black_setting') else None
    res = {
        # 'sidebar_background': admin_black_setting.sidebar_background if admin_black_setting else 'primary',
        # 'dark_mode': admin_black_setting.dark_mode if admin_black_setting else True,
        # 'input_bg_color': '#ffffff' if admin_black_setting and not admin_black_setting.dark_mode else '#27293c'
    }

    return res


@register.simple_tag
def paginator_number(cl, i):
    """
    Generate an individual page index link in a paginated list.
    """
    if i == cl.paginator.ELLIPSIS:
        return format_html('{} ', cl.paginator.ELLIPSIS)
    elif i == cl.page_num:
        return format_html('<a href="" class="page-link">{}</a> ', i)
    else:
        return format_html(
            '<a href="{}" class="page-link {}">{}</a> ',
            cl.get_query_string({PAGE_VAR: i}),
            mark_safe('end' if i == cl.paginator.num_pages else ''),
            i,
        )


@register.filter
def sum_number(value, number):
    return value + number


@register.filter
def neg_num(value, number):
    return value - number

================
File: home/templatetags/replace_value.py
================
from django import template

register = template.Library()

@register.filter(name='replace_value')
def replace_value(value, arg):
    """Removes all values of arg from the given string"""
    return value.replace(arg, ' ').title()

@register.filter(name='clean_title')
def clean_title(text):
    return text.replace('#','').strip().replace('\n','').replace('\r,','')

@register.filter(name='dict2json')
def dict_to_json(dictionary):
    return json.dumps(dictionary)

@register.simple_tag
def client_data(client):
    client_json = json.dumps(client)
    return mark_safe(client_json)

================
File: home/admin.py
================
from django.contrib import admin

# Register your models here.

================
File: home/apps.py
================
from django.apps import AppConfig


class HomeConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'home'

================
File: home/forms.py
================
from django import forms
from django.contrib.auth.forms import UserCreationForm, AuthenticationForm, PasswordChangeForm, UsernameField, PasswordResetForm, SetPasswordForm
from django.contrib.auth.models import User
from django.utils.translation import gettext_lazy as _


class RegistrationForm(UserCreationForm):
  password1 = forms.CharField(
      label=_("Password"),
      widget=forms.PasswordInput(attrs={'class': 'form-control', "placeholder": "Password"}),
  )
  password2 = forms.CharField(
      label=_("Password Confirmation"),
      widget=forms.PasswordInput(attrs={'class': 'form-control', "placeholder": "Confirm Password"}),
  )

  class Meta:
    model = User
    fields = ('username', 'email', )

    widgets = {
      'username': forms.TextInput(attrs={
          'class': 'form-control',
          "placeholder": "Username",
      }),
      'email': forms.EmailInput(attrs={
          'class': 'form-control',
          "placeholder": "Email"
      })
    }


class LoginForm(AuthenticationForm):
  username = UsernameField(widget=forms.TextInput(attrs={"class": "form-control", "placeholder": "Username"}))
  password = forms.CharField(
      label=_("Password"),
      strip=False,
      widget=forms.PasswordInput(attrs={"class": "form-control", "placeholder": "Password"}),
  )

class UserPasswordResetForm(PasswordResetForm):
    email = forms.EmailField(widget=forms.EmailInput(attrs={
        'class': 'form-control',
        "placeholder": "Email",
    }))

class UserSetPasswordForm(SetPasswordForm):
    new_password1 = forms.CharField(max_length=50, widget=forms.PasswordInput(attrs={
        'class': 'form-control',
        "placeholder": "New Password",
    }), label="New Password")
    new_password2 = forms.CharField(max_length=50, widget=forms.PasswordInput(attrs={
        'class': 'form-control',
        "placeholder": "Confirm New Password"
    }), label="Confirm New Password")
    

class UserPasswordChangeForm(PasswordChangeForm):
    old_password = forms.CharField(max_length=50, widget=forms.PasswordInput(attrs={
        'class': 'form-control',
        "placeholder": "Old Password"
    }), label='Old Password')
    new_password1 = forms.CharField(max_length=50, widget=forms.PasswordInput(attrs={
        'class': 'form-control',
        "placeholder": "New Password"
    }), label="New Password")
    new_password2 = forms.CharField(max_length=50, widget=forms.PasswordInput(attrs={
        'class': 'form-control',
        "placeholder": "Confirm New Password"
    }), label="Confirm New Password")

================
File: home/models.py
================
from django.db import models

# Create your models here.

================
File: home/tests.py
================
from django.test import TestCase

# Create your tests here.

================
File: home/urls.py
================
from django.urls import path
from home import views
from django.contrib.auth import views as auth_views


urlpatterns = [
  # Dashboard
  path('', views.default, name="index"),
  path('automotive', views.automotive, name="automotive"),
  path('smart-home', views.smart_home, name="smart_home"),
  path('crm', views.crm, name="crm"),
  # Dashboard -> VR
  path('vr/vr-default/', views.vr_default, name="vr_default"),
  path('vr/vr-info/', views.vr_info, name="vr_info"),

  # Pages
  path('pages/messages/', views.messages, name="messages"),
  path('pages/widgets/', views.widgets, name="widgets"),
  path('pages/charts/', views.charts, name="charts"),
  path('pages/sweet-alerts/', views.sweet_alerts, name="sweet_alerts"),
  path('pages/notifications/', views.notifications, name="notifications"),
  path('pages/pricing-page/', views.pricing_page, name="pricing"),
  path('pages/rtl/', views.rtl, name="rtl"),
  # Pages -> Profile
  path('pages/profile/profile-overview/', views.profile_overview, name="profile_overview"), 
  path('pages/profile/teams/', views.teams, name="teams"), 
  path('pages/profile/projects/', views.projects, name="projects"), 
  # Pages -> Users
  path('pages/users/reports/', views.reports, name="reports"),
  path('pages/users/new-user/', views.new_user, name="new_user"),
  # Pages -> Accounts
  path('pages/accounts/settings/', views.settings, name="settings"),
  path('pages/accounts/billing/', views.billing, name="billing"),
  path('pages/accounts/invoice/', views.invoice, name="invoice"),
  path('pages/accounts/security/', views.security, name="security"),
  # Pages -> Porjects
  path('pages/projects/general/', views.general, name="general"),
  path('pages/projects/timeline/', views.timeline, name="timeline"),
  path('pages/projects/new-project/', views.new_project, name="new_project"),

  # Applications
  path('applications/kanban/', views.kanban, name="kanban"),
  path('applications/wizard/', views.wizard, name="wizard"),
  path('applications/datatables/', views.datatables, name="datatables"),
  path('applications/calendar/', views.calendar, name="calendar"),
  path('applications/analytics/', views.analytics, name="analytics"),

  # Ecommerce
  path('ecommerce/overview/', views.overview, name="overview"),
  path('ecommerce/referral/', views.referral, name="referral"),
  # Ecommerce -> Products
  path('ecommerce/products/new-product/', views.new_product, name="new_product"),
  path('ecommerce/products/edit-product/', views.edit_product, name="edit_product"),
  path('ecommerce/products/product-page/', views.product_page, name="product_page"),
  path('ecommerce/products/products-list/', views.products_list, name="products_list"),
  # Ecommerce -> Orders
  path('ecommerce/orders/order-list', views.order_list, name="order_list"),
  path('ecommerce/orders/order-details', views.order_details, name="order_details"),

  # Authentication -> Register
  path('accounts/register/basic-register/', views.basic_register, name="basic_register"),
  path('accounts/register/cover-register/', views.cover_register, name="cover_register"),
  path('accounts/register/illustration-register/', views.illustration_register, name="illustration_register"),
  # Authentication -> Login
  path('accounts/login/basic-login/', views.BasicLoginView.as_view(), name="basic_login"),
  path('accounts/login/cover-login/', views.CoverLoginView.as_view(), name="cover_login"),
  path('accounts/login/illustration-login/', views.IllustrationLoginView.as_view(), name="illustration_login"),
  # Authentication -> Reset
  path('accounts/reset/basic-reset/', views.BasicResetView.as_view(), name="basic_reset"),
  path('accounts/reset/cover-reset/', views.CoverResetView.as_view(), name="cover_reset"),
  path('accounts/reset/illustration-reset/', views.IllustrationResetView.as_view(), name="illustration_reset"),

  path('accounts/password-change/', views.UserPasswordChangeView.as_view(), name='password_change'),
  path('accounts/password-change-done/', auth_views.PasswordChangeDoneView.as_view(
      template_name='accounts/done/change-done.html'
  ), name="password_change_done"),
  path('accounts/password-reset-done/', auth_views.PasswordResetDoneView.as_view(
      template_name='accounts/done/basic.html'
  ), name='password_reset_done'),
  path('accounts/password-reset-confirm/<uidb64>/<token>/', 
      views.UserPasswordResetConfirmView.as_view(), name='password_reset_confirm'),
  path('accounts/password-reset-complete/', auth_views.PasswordResetCompleteView.as_view(
      template_name='accounts/complete/basic.html'
  ), name='password_reset_complete'),

  # Authentication -> Lock
  path('accounts/lock/basic-lock/', views.basic_lock, name="basic_lock"),
  path('accounts/lock/cover-lock/', views.cover_lock, name="cover_lock"),
  path('accounts/lock/illustration-lock/', views.illustration_lock, name='illustration_lock'),
  # Authentication -> Verification
  path('accounts/verification/basic-verification/', views.basic_verification, name="basic_verification"),
  path('accounts/verification/cover-verification/', views.cover_verification, name="cover_verification"),
  path('accounts/verification/illustration-verification/', views.illustration_verification, name="illustration_verification"),
  # Error
  path('error/404/', views.error_404, name="error_404"),
  path('error/500/', views.error_500, name="error_500"),
  path('logout/', views.logout_view, name="logout"),
]

================
File: home/utils.py
================
# -*- encoding: utf-8 -*-
"""
Copyright (c) 2019 - present AppSeed.us
"""

import datetime
import json
from django.template import Context
from django.utils import translation

try:
    from django.apps.registry import apps
except ImportError:
    try:
        from django.apps import apps  # Fix Django 1.7 import issue
    except ImportError:
        pass
from django.core.serializers.json import DjangoJSONEncoder
from django.http import HttpResponse

try:
    from django.core.urlresolvers import reverse, resolve, NoReverseMatch
except ImportError:  # Django 1.11
    from django.urls import reverse, resolve, NoReverseMatch

from django.contrib.admin import AdminSite
from django.utils.text import capfirst
from django.contrib import messages
from django.contrib.admin.options import IncorrectLookupParameters
from django.contrib import admin
from django.utils.text import slugify

try:
    from django.utils.translation import ugettext_lazy as _
except ImportError:
    from django.utils.translation import gettext_lazy as _  # Django 4.0.0 and more

try:
    from collections import OrderedDict
except ImportError:
    from ordereddict import OrderedDict  # Python 2.6


default_apps_icon = {
    'auth': 'fa fa-users'
}


class JsonResponse(HttpResponse):
    """
    An HTTP response class that consumes data to be serialized to JSON.
    :param data: Data to be dumped into json. By default only ``dict`` objects
      are allowed to be passed due to a security flaw before EcmaScript 5. See
      the ``safe`` parameter for more information.
    :param encoder: Should be an json encoder class. Defaults to
      ``django.core.serializers.json.DjangoJSONEncoder``.
    :param safe: Controls if only ``dict`` objects may be serialized. Defaults
      to ``True``.
    """

    def __init__(self, data, encoder=DjangoJSONEncoder, safe=True, **kwargs):
        if safe and not isinstance(data, dict):
            raise TypeError('In order to allow non-dict objects to be '
                            'serialized set the safe parameter to False')
        kwargs.setdefault('content_type', 'application/json')
        data = json.dumps(data, cls=encoder)
        super(JsonResponse, self).__init__(content=data, **kwargs)


def get_app_list(context, order=True):
    admin_site = get_admin_site(context)
    request = context['request']

    app_dict = {}
    for model, model_admin in admin_site._registry.items():

        app_icon = model._meta.app_config.icon if hasattr(model._meta.app_config, 'icon') else None
        app_label = model._meta.app_label
        try:
            has_module_perms = model_admin.has_module_permission(request)
        except AttributeError:
            has_module_perms = request.user.has_module_perms(app_label)  # Fix Django < 1.8 issue

        if has_module_perms:
            perms = model_admin.get_model_perms(request)

            # Check whether user has any perm for this module.
            # If so, add the module to the model_list.
            if True in perms.values():
                info = (app_label, model._meta.model_name)
                model_dict = {
                    'name': capfirst(model._meta.verbose_name_plural),
                    'object_name': model._meta.object_name,
                    'perms': perms,
                    'model_name': model._meta.model_name
                }
                if perms.get('change', False) or perms.get("view", False):
                    try:
                        model_dict['admin_url'] = reverse('admin:%s_%s_changelist' % info, current_app=admin_site.name)
                    except NoReverseMatch:
                        pass
                if perms.get('add', False):
                    try:
                        model_dict['add_url'] = reverse('admin:%s_%s_add' % info, current_app=admin_site.name)
                    except NoReverseMatch:
                        pass
                if app_label in app_dict:
                    app_dict[app_label]['models'].append(model_dict)
                else:
                    try:
                        name = apps.get_app_config(app_label).verbose_name
                    except NameError:
                        name = app_label.title()
                    app_dict[app_label] = {
                        'name': name,
                        'app_label': app_label,
                        'app_url': reverse(
                            'admin:app_list',
                            kwargs={'app_label': app_label},
                            current_app=admin_site.name,
                        ),
                        'has_module_perms': has_module_perms,
                        'models': [model_dict],
                    }

                if not app_icon:
                    app_icon = default_apps_icon[app_label] if app_label in default_apps_icon else None
                app_dict[app_label]['icon'] = app_icon

    # Sort the apps alphabetically.
    app_list = list(app_dict.values())

    if order:
        app_list.sort(key=lambda x: x['name'].lower())

        # Sort the models alphabetically within each app.
        for app in app_list:
            app['models'].sort(key=lambda x: x['name'])

    return app_list


def get_admin_site(context):
    try:
        current_resolver = resolve(context.get('request').path)
        index_resolver = resolve(reverse('%s:index' % current_resolver.namespaces[0]))

        if hasattr(index_resolver.func, 'admin_site'):
            return index_resolver.func.admin_site

        for func_closure in index_resolver.func.__closure__:
            if isinstance(func_closure.cell_contents, AdminSite):
                return func_closure.cell_contents
    except:
        pass

    return admin.site


def get_admin_site_name(context):
    return get_admin_site(context).name


class SuccessMessageMixin(object):
    """
    Adds a success message on successful form submission.
    """
    success_message = ''

    def form_valid(self, form):
        response = super(SuccessMessageMixin, self).form_valid(form)
        success_message = self.get_success_message(form.cleaned_data)
        if success_message:
            messages.success(self.request, success_message)
        return response

    def get_success_message(self, cleaned_data):
        return self.success_message % cleaned_data


def get_model_queryset(admin_site, model, request, preserved_filters=None):
    model_admin = admin_site._registry.get(model)

    if model_admin is None:
        return

    try:
        changelist_url = reverse('%s:%s_%s_changelist' % (
            admin_site.name,
            model._meta.app_label,
            model._meta.model_name
        ))
    except NoReverseMatch:
        return

    changelist_filters = None

    if preserved_filters:
        changelist_filters = preserved_filters.get('_changelist_filters')

    if changelist_filters:
        changelist_url += '?' + changelist_filters

    if model_admin:
        queryset = model_admin.get_queryset(request)
    else:
        queryset = model.objects

    list_display = model_admin.get_list_display(request)
    list_display_links = model_admin.get_list_display_links(request, list_display)
    list_filter = model_admin.get_list_filter(request)
    search_fields = model_admin.get_search_fields(request) \
        if hasattr(model_admin, 'get_search_fields') else model_admin.search_fields
    list_select_related = model_admin.get_list_select_related(request) \
        if hasattr(model_admin, 'get_list_select_related') else model_admin.list_select_related

    actions = model_admin.get_actions(request)
    if actions:
        list_display = ['action_checkbox'] + list(list_display)

    ChangeList = model_admin.get_changelist(request)

    change_list_args = [
        request, model, list_display, list_display_links, list_filter,
        model_admin.date_hierarchy, search_fields, list_select_related,
        model_admin.list_per_page, model_admin.list_max_show_all,
        model_admin.list_editable, model_admin]

    try:
        sortable_by = model_admin.get_sortable_by(request)
        change_list_args.append(sortable_by)
    except AttributeError:
        # django version < 2.1
        pass

    try:
        cl = ChangeList(*change_list_args)
        queryset = cl.get_queryset(request)
    except IncorrectLookupParameters:
        pass

    return queryset


def get_possible_language_codes():
    language_code = translation.get_language()

    language_code = language_code.replace('_', '-').lower()
    language_codes = []

    # making dialect part uppercase
    split = language_code.split('-', 2)
    if len(split) == 2:
        language_code = '%s-%s' % (split[0].lower(), split[1].upper()) if split[0] != split[1] else split[0]

    language_codes.append(language_code)

    # adding language code without dialect part
    if len(split) == 2:
        language_codes.append(split[0].lower())

    return language_codes


def get_original_menu_items(context):
    if context.get('user') and user_is_authenticated(context['user']):
        # pinned_apps = PinnedApplication.objects.filter(user=context['user'].pk).values_list('app_label', flat=True)
        pinned_apps = []
    else:
        pinned_apps = []

    original_app_list = get_app_list(context)

    return map(lambda app: {
        'app_label': app['app_label'],
        'url': app['app_url'],
        'url_blank': False,
        'label': app.get('name', capfirst(_(app['app_label']))),
        'has_perms': app.get('has_module_perms', False),
        'icon': app.get('icon', None),
        'models': list(map(lambda model: {
            'url': model.get('admin_url'),
            'url_blank': False,
            'name': model['model_name'],
            'object_name': model['object_name'],
            'label': model.get('name', model['object_name']),
            'has_perms': any(model.get('perms', {}).values()),
        }, app['models'])),
        'pinned': app['app_label'] in pinned_apps,
        'custom': False
    }, original_app_list)


def get_menu_item_url(url, original_app_list):
    if isinstance(url, dict):
        url_type = url.get('type')

        if url_type == 'app':
            return original_app_list[url['app_label']]['url']
        elif url_type == 'model':
            models = dict(map(
                lambda x: (x['name'], x['url']),
                original_app_list[url['app_label']]['models']
            ))
            return models[url['model']]
        elif url_type == 'reverse':
            return reverse(url['name'], args=url.get('args'), kwargs=url.get('kwargs'))
    elif isinstance(url, str):
        return url


def get_menu_items(context):
    # pinned_apps = PinnedApplication.objects.filter(user=context['user'].pk).values_list('app_label', flat=True)
    pinned_apps = []
    original_app_list = OrderedDict(map(lambda app: (app['app_label'], app), get_original_menu_items(context)))
    custom_app_list = None
    custom_app_list_deprecated = None

    if custom_app_list not in (None, False):
        if isinstance(custom_app_list, dict):
            admin_site = get_admin_site(context)
            custom_app_list = custom_app_list.get(admin_site.name, [])

        app_list = []

        def get_menu_item_app_model(app_label, data):
            item = {'has_perms': True}

            if 'name' in data:
                parts = data['name'].split('.', 2)

                if len(parts) > 1:
                    app_label, name = parts
                else:
                    name = data['name']

                if app_label in original_app_list:
                    models = dict(map(
                        lambda x: (x['name'], x),
                        original_app_list[app_label]['models']
                    ))

                    if name in models:
                        item = models[name].copy()

            if 'label' in data:
                item['label'] = data['label']

            if 'url' in data:
                item['url'] = get_menu_item_url(data['url'], original_app_list)

            if 'url_blank' in data:
                item['url_blank'] = data['url_blank']

            if 'permissions' in data:
                item['has_perms'] = item.get('has_perms', True) and context['user'].has_perms(data['permissions'])

            return item

        def get_menu_item_app(data):
            app_label = data.get('app_label')

            if not app_label:
                if 'label' not in data:
                    raise Exception('Custom menu items should at least have \'label\' or \'app_label\' key')
                app_label = 'custom_%s' % slugify(data['label'], allow_unicode=True)

            if app_label in original_app_list:
                item = original_app_list[app_label].copy()
            else:
                item = {'app_label': app_label, 'has_perms': True}

            if 'label' in data:
                item['label'] = data['label']

            if 'items' in data:
                item['items'] = list(map(lambda x: get_menu_item_app_model(app_label, x), data['items']))

            if 'url' in data:
                item['url'] = get_menu_item_url(data['url'], original_app_list)

            if 'url_blank' in data:
                item['url_blank'] = data['url_blank']

            if 'permissions' in data:
                item['has_perms'] = item.get('has_perms', True) and context['user'].has_perms(data['permissions'])

            item['pinned'] = item['app_label'] in pinned_apps

            return item

        for data in custom_app_list:
            item = get_menu_item_app(data)
            app_list.append(item)
    elif custom_app_list_deprecated not in (None, False):
        app_dict = {}
        models_dict = {}

        for app in original_app_list.values():
            app_label = app['app_label']
            app_dict[app_label] = app

            for model in app['models']:
                if app_label not in models_dict:
                    models_dict[app_label] = {}

                models_dict[app_label][model['object_name']] = model

            app['items'] = []

        app_list = []

        if isinstance(custom_app_list_deprecated, dict):
            admin_site = get_admin_site(context)
            custom_app_list_deprecated = custom_app_list_deprecated.get(admin_site.name, [])

        for item in custom_app_list_deprecated:
            app_label, models = item

            if app_label in app_dict:
                app = app_dict[app_label]

                for model_label in models:
                    if model_label == '__all__':
                        app['items'] = models_dict[app_label].values()
                        break
                    elif model_label in models_dict[app_label]:
                        model = models_dict[app_label][model_label]
                        app['items'].append(model)

                app_list.append(app)
    else:
        def map_item(item):
            item['items'] = item['models']
            return item

        app_list = list(map(map_item, original_app_list.values()))

    current_found = False

    for app in app_list:
        if not current_found:
            for model in app['items']:
                if not current_found and model.get('url') and context['request'].path.startswith(model['url']):
                    model['current'] = True
                    current_found = True
                else:
                    model['current'] = False

            if not current_found and app.get('url') and context['request'].path.startswith(app['url']):
                app['current'] = True
                current_found = True
            else:
                app['current'] = False

    return app_list


def context_to_dict(context):
    if isinstance(context, Context):
        flat = {}
        for d in context.dicts:
            flat.update(d)
        context = flat

    return context


def user_is_authenticated(user):
    if not hasattr(user.is_authenticated, '__call__'):
        return user.is_authenticated
    else:
        return user.is_authenticated()

================
File: home/views.py
================
from django.shortcuts import render, redirect
from django.contrib.auth.views import LoginView, PasswordResetView, PasswordChangeView, PasswordResetConfirmView
from home.forms import RegistrationForm, LoginForm, UserPasswordResetForm, UserSetPasswordForm, UserPasswordChangeForm
from django.contrib.auth import logout

from django.contrib.auth.decorators import login_required

# Dashboard
def default(request):
  context = {
    'parent': 'dashboard',
    'segment': 'default'
  }
  return render(request, 'pages/dashboards/default.html', context)

def automotive(request):
  context = {
    'parent': 'dashboard',
    'segment': 'automotive'
  }
  return render(request, 'pages/dashboards/automotive.html', context)

def smart_home(request):
  context = {
    'parent': 'dashboard',
    'segment': 'smart_home'
  }
  return render(request, 'pages/dashboards/smart-home.html', context)

def crm(request):
  context = {
    'parent': 'dashboard',
    'segment': 'crm'
  }
  return render(request, 'pages/dashboards/crm.html', context)

# Dashboard -> VR
def vr_default(request):
  context = {
    'parent': 'dashboard',
    'sub_parent': 'vr',
    'segment': 'vr_default'
  }
  return render(request, 'pages/dashboards/vr/vr-default.html', context)

def vr_info(request):
  context = {
    'parent': 'dashboard',
    'sub_parent': 'vr',
    'segment': 'vr_info'
  }
  return render(request, 'pages/dashboards/vr/vr-info.html', context)

# Pages
def messages(request):
  context = {
    'parent': 'pages',
    'segment': 'messages'
  }
  return render(request, 'pages/messages.html', context)

def widgets(request):
  context = {
    'parent': 'pages',
    'segment': 'widgets'
  }
  return render(request, 'pages/widgets.html', context)

def charts(request):
  context = {
    'parent': 'pages',
    'segment': 'charts'
  }
  return render(request, 'pages/charts.html', context)

def sweet_alerts(request):
  context = {
    'parent': 'pages',
    'segment': 'sweet_alerts'
  }
  return render(request, 'pages/sweet-alerts.html', context)

def notifications(request):
  context = {
    'parent': 'pages',
    'segment': 'notifications'
  }
  return render(request, 'pages/notifications.html', context)

def pricing_page(request):
  return render(request, 'pages/pricing-page.html')

def rtl(request):
  return render(request, 'pages/rtl-page.html')

# Pages -> Profile
def profile_overview(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'profile',
    'segment': 'profile_overview'
  }
  return render(request, 'pages/profile/overview.html', context)

def teams(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'profile',
    'segment': 'teams'
  }
  return render(request, 'pages/profile/teams.html', context)

def projects(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'profile',
    'segment': 'projects'
  }
  return render(request, 'pages/profile/projects.html', context)

# Pages -> Users
def reports(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'users',
    'segment': 'reports'
  }
  return render(request, 'pages/users/reports.html', context)

def new_user(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'users',
    'segment': 'new_user'
  }
  return render(request, 'pages/users/new-user.html', context)

# Pages -> Accounts
def settings(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'accounts',
    'segment': 'settings'
  }
  return render(request, 'pages/account/settings.html', context)

def billing(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'accounts',
    'segment': 'billing'
  }
  return render(request, 'pages/account/billing.html', context)

def invoice(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'accounts',
    'segment': 'invoice'
  }
  return render(request, 'pages/account/invoice.html', context)

def security(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'accounts',
    'segment': 'security'
  }
  return render(request, 'pages/account/security.html', context)

# Pages -> Projects
def general(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'projects',
    'segment': 'general'
  }
  return render(request, 'pages/projects/general.html', context)

def timeline(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'projects',
    'segment': 'timeline'
  }
  return render(request, 'pages/projects/timeline.html', context)

def new_project(request):
  context = {
    'parent': 'pages',
    'sub_parent': 'projects',
    'segment': 'new_project'
  }
  return render(request, 'pages/projects/new-project.html', context)

# Applications
def kanban(request):
  context = {
    'parent': 'applications',
    'segment': 'kanban'
  }
  return render(request, 'pages/applications/kanban.html', context)

def wizard(request):
  context = {
    'parent': 'applications',
    'segment': 'wizard'
  }
  return render(request, 'pages/applications/wizard.html', context)

def datatables(request):
  context = {
    'parent': 'applications',
    'segment': 'datatables'
  }
  return render(request, 'pages/applications/datatables.html', context)

def calendar(request):
  context = {
    'parent': 'applications',
    'segment': 'calendar'
  }
  return render(request, 'pages/applications/calendar.html', context)

def analytics(request):
  context = {
    'parent': 'applications',
    'segment': 'analytics'
  }
  return render(request, 'pages/applications/analytics.html', context)

# Ecommerce
def overview(request):
  context = {
    'parent': 'ecommerce',
    'segment': 'overview'
  }
  return render(request, 'pages/ecommerce/overview.html', context)

def referral(request):
  context = {
    'parent': 'ecommerce',
    'segment': 'referral'
  }
  return render(request, 'pages/ecommerce/referral.html', context)

# Ecommerce -> Products
def new_product(request):
  context = {
    'parent': 'ecommerce',
    'sub_parent': 'products',
    'segment': 'new_product'
  }
  return render(request, 'pages/ecommerce/products/new-product.html', context)

def edit_product(request):
  context = {
    'parent': 'ecommerce',
    'sub_parent': 'products',
    'segment': 'edit_product'
  }
  return render(request, 'pages/ecommerce/products/edit-product.html', context)

def product_page(request):
  context = {
    'parent': 'ecommerce',
    'sub_parent': 'products',
    'segment': 'product_page'
  }
  return render(request, 'pages/ecommerce/products/product-page.html', context)

def products_list(request):
  context = {
    'parent': 'ecommerce',
    'sub_parent': 'products',
    'segment': 'products_list'
  }
  return render(request, 'pages/ecommerce/products/products-list.html', context)

# Ecommerce -> Orders
def order_list(request):
  context = {
    'parent': 'ecommerce',
    'sub_parent': 'orders',
    'segment': 'order_list'
  }
  return render(request, 'pages/ecommerce/orders/list.html', context)

def order_details(request):
  context = {
    'parent': 'ecommerce',
    'sub_parent': 'orders',
    'segment': 'order_details'
  }
  return render(request, 'pages/ecommerce/orders/details.html', context)

# Authentication -> Register
def basic_register(request):
  if request.method == 'POST':
    form = RegistrationForm(request.POST)
    if form.is_valid():
      form.save()
      return redirect('/accounts/login/basic-login/')
  else:
    form = RegistrationForm()
  
  context = {'form': form}
  return render(request, 'accounts/signup/basic.html', context)

def cover_register(request):
  if request.method == 'POST':
    form = RegistrationForm(request.POST)
    if form.is_valid():
      form.save()
      return redirect('/accounts/login/cover-login/')
  else:
    form = RegistrationForm()

  context = {'form': form}
  return render(request, 'accounts/signup/cover.html', context)

def illustration_register(request):
  if request.method == 'POST':
    form = RegistrationForm(request.POST)
    if form.is_valid():
      form.save()
      return redirect('/accounts/login/illustration-login/')
  else:
    form = RegistrationForm()

  context = {'form': form}
  return render(request, 'accounts/signup/illustration.html', context)

# Authentication -> Login
class BasicLoginView(LoginView):
  template_name = 'accounts/signin/basic.html'
  form_class = LoginForm

class CoverLoginView(LoginView):
  template_name = 'accounts/signin/cover.html'
  form_class = LoginForm

class IllustrationLoginView(LoginView):
  template_name = 'accounts/signin/illustration.html'
  form_class = LoginForm

# Authentication -> Reset
class BasicResetView(PasswordResetView):
  template_name = 'accounts/reset/basic.html'
  form_class = UserPasswordResetForm

class CoverResetView(PasswordResetView):
  template_name = 'accounts/reset/cover.html'
  form_class = UserPasswordResetForm

class IllustrationResetView(PasswordResetView):
  template_name = 'accounts/reset/illustration.html'
  form_class = UserPasswordResetForm


class UserPasswordResetConfirmView(PasswordResetConfirmView):
  template_name = 'accounts/reset-confirm/basic.html'
  form_class = UserSetPasswordForm

class UserPasswordChangeView(PasswordChangeView):
  template_name = 'accounts/change/basic.html'
  form_class = UserPasswordChangeForm

# Authentication -> Lock
def basic_lock(request):
  return render(request, 'accounts/lock/basic.html')

def cover_lock(request):
  return render(request, 'accounts/lock/cover.html')

def illustration_lock(request):
  return render(request, 'accounts/lock/illustration.html')

# Authentication -> Verification
def basic_verification(request):
  return render(request, 'accounts/verification/basic.html')

def cover_verification(request):
  return render(request, 'accounts/verification/cover.html')

def illustration_verification(request):
  return render(request, 'accounts/verification/illustration.html')

# Error
def error_404(request,exception=None ):
  return render(request, 'accounts/error/404.html')

def error_500(request, exception=None):
  return render(request, 'accounts/error/500.html')

def logout_view(request):
  logout(request)
  return redirect('/accounts/login/illustration-login/')



# i18n
def i18n_view(request):
  context = {
    'parent': 'apps',
    'segment': 'i18n'
  }
  return render(request, 'pages/apps/i18n.html', context)
