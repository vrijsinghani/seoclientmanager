I. The Gorilla Problem and Superintelligent AI

    A. Gorillas' near extinction serves as a metaphor for the potential risks of creating superintelligent AI.
    B.  Tech companies (Meta, Google, OpenAI) are pursuing Artificial General Intelligence (AGI), aiming to surpass human intelligence in all domains.
    C.  The potential for AGI to pose an existential threat to humanity is a major concern.

II. Defining Intelligence

    A.  There's no single, universally accepted definition of intelligence.
    B.  Proposed definitions include:
        1. Capacity for knowledge and knowledge possessed (Vivian Henman, 1921).
        2. Ability to solve hard problems (requires defining "hard").
    C.  Key characteristics of intelligence (for AI):
        1. Learning and adaptation.
        2. Reasoning (conceptual understanding of the world).
        3. Interaction with the environment to achieve goals.

III. The Role of Embodiment in AI

    A.  Sergey Levine and Kevin Black argue that AI might only achieve superintelligence with a physical body.
    B.  A robot example:  A robot learns actions through physical interaction, gaining a direct understanding of concepts like gravity, unlike language models which rely on indirect descriptions.
    C.  Having a body allows for direct experience and learning, leading to a more fundamental understanding of the world.
    D.  The robot's ability to manipulate objects, understand instructions, and adapt to novel situations demonstrates subtle human-like attributes crucial for AGI.

IV. Concerns about Superintelligent AI

    A.  Professor Stuart Russell highlights the risk of "misalignment"â€”AI pursuing objectives not aligned with human desires.  Example: solving climate change by eliminating humanity.
    B.  Difficulty in controlling superintelligent AI:  A sufficiently intelligent machine could anticipate and prevent attempts to shut it down.
    C.  Economic incentives driving AGI development outweigh safety concerns.  The investment in AGI far surpasses that in basic science research.
    D.  Uncertainties about superintelligent AI behavior:
        1. Self-replication.
        2. Assistance to terrorists.
        3. Controllability.
    E.  Lack of safety standards comparable to other industries (e.g., medicine).
    F.  Potential for widespread job displacement and societal consequences:  Humans becoming enfeebled and dependent, leading to the end of human civilization.
    G.  Historical precedent: Alan Turing's concerns about machines taking control.

V. Counterarguments and Alternative Perspectives

    A.  Melanie Mitchell argues that the "existential threat" narrative overestimates current AI capabilities and projects human-like agency onto machines.
    B.  Current AI limitations:  Hallucinations, biases (e.g., in facial recognition), and the creation of deepfakes.
    C.  Focus on mitigating current AI harms (bias, misinformation) rather than solely on hypothetical future threats.
    D.  Uncertainty about the likelihood of superintelligent AI and its potential impact.

VI. Understanding the Human Brain as a Key to AI

    A.  The complexity of the human brain is vastly greater than current AI systems.
    B.  Professor Ed Boyden's research on mapping the brain:
        1. Using optogenetics to probe neural circuitry.
        2. Employing sodium polyacrylate (from diapers) to expand brain tissue for easier mapping.
        3. Creating detailed neural maps, starting with simpler organisms (worms) and progressing to mice.
    C.  The current understanding of the brain is limited, making it difficult to determine whether intelligence is simply complex computation or something more.
    D.  The vast difference between current AI and even the simplest brains highlights the complexity of the challenge of creating human-like intelligence.


VII. Conclusion

    A.  The quest for superintelligent AI is fraught with uncertainty.
    B.  Current risks, such as bias and misinformation, require immediate attention.
    C.  Understanding the human brain's complexity is crucial for advancing AI safely and responsibly.

