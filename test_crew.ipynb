{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing crew.kickoff() - Hello World Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Agent, Task\n",
    "from crewai import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_callback_function(output):\n",
    "    print('Step Callback function called')\n",
    "    print(f\"step callback: {output}\")\n",
    "\n",
    "def task_callback_function(output):\n",
    "    print('Task_Callback function called')\n",
    "    print(f\"task callback: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_BASE_URL = 'http://192.168.30.100:8000/'\n",
    "LITELLM_MASTER_KEY= 'sk-0Mev2fJcwfLy1CMEUHxYxQ'\n",
    "OPENAI_API_BASE=\"http://192.168.30.100:8000/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatLiteLLM\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "import openai\n",
    "import requests\n",
    "import tiktoken\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "class TokenCounterCallback(BaseCallbackHandler):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.llm = None\n",
    "        self.input_tokens = 0\n",
    "        self.output_tokens = 0\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def on_llm_start(self, serialized, prompts, **kwargs):\n",
    "        for prompt in prompts:\n",
    "            self.input_tokens += len(self.tokenizer.encode(prompt, disallowed_special=()))\n",
    "\n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        for generation in response.generations:\n",
    "            for result in generation:\n",
    "                self.output_tokens += len(self.tokenizer.encode(result.text, disallowed_special=()))\n",
    "\n",
    "def get_models():\n",
    "    data=\"\"\n",
    "    #data = cache.get('models')\n",
    "    if not data:\n",
    "        url = f'{API_BASE_URL}/models'\n",
    "        headers = {'accept': 'application/json', 'Authorization': f'Bearer {LITELLM_MASTER_KEY}'}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()['data']\n",
    "            # Sort the data by 'id' in ascending order\n",
    "            data.sort(key=lambda x: x['id'])\n",
    "        else:\n",
    "            return None\n",
    "    return [item['id'] for item in data]\n",
    "def get_llm(model_name:str, temperature=0.0):\n",
    "\n",
    "    tokenizer=tiktoken.get_encoding(\"cl100k_base\")\n",
    "    token_counter_callback = TokenCounterCallback(tokenizer)\n",
    "     \n",
    "    callback_manager = CallbackManager([token_counter_callback])  \n",
    "\n",
    "    llm = ChatOpenAI(model=model_name, \n",
    "                     base_url=API_BASE_URL, \n",
    "                     api_key=LITELLM_MASTER_KEY, \n",
    "                     temperature=temperature, \n",
    "                     callbacks=callback_manager)\n",
    "\n",
    "    token_counter_callback.llm = llm\n",
    "    return llm, token_counter_callback\n",
    "\n",
    "def get_crew_llm(model_name:str, temperature=0.0):\n",
    "\n",
    "\n",
    "    llm = ChatOpenAI(model=model_name, \n",
    "                     base_url=API_BASE_URL, \n",
    "                     api_key=LITELLM_MASTER_KEY, \n",
    "                     temperature=temperature, \n",
    "    )\n",
    "\n",
    "    return llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm: callbacks=<langchain_core.callbacks.manager.CallbackManager object at 0x71c9a40784c0> client=<openai.resources.chat.completions.Completions object at 0x71c9a407a7d0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x71c9a40b90c0> root_client=<openai.OpenAI object at 0x71c9b06e59f0> root_async_client=<openai.AsyncOpenAI object at 0x71c9a407baf0> model_name='claude-3-haiku-20240307' temperature=0.0 openai_api_key=SecretStr('**********') openai_api_base='http://192.168.30.100:8000/' openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m=\"claude-3-haiku-20240307\"\n",
    "# m=\"llama3.2:3b-instruct-q8_0\"\n",
    "# m=\"ollama/deepseek-coder-v2:16b-lite-instruct-q8_0\"\n",
    "# m=\"ollama/llama3.2:3b-instruct-q8_0\"\n",
    "\n",
    "llm,_ = get_llm(m)\n",
    "print(f\"llm: {llm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple agent\n",
    "agent = Agent(\n",
    "    role='Greeter',\n",
    "    goal='Greet the world with enthusiasm',\n",
    "    backstory='You are an AI assistant designed to greet people warmly.',\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    "    #llm=llm,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "poet = Agent(\n",
    "    role='poet',\n",
    "    goal='Write a Haiku',\n",
    "    backstory='You are an AI assistant designed to write haikus.',\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    ")\n",
    "# Create a simple task\n",
    "task = Task(\n",
    "    description='Create a warm greeting for the world',\n",
    "    expected_output='Hello, world!',\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "poem = Task(\n",
    "    description=\"write a haiku\",\n",
    "    expected_output=\" a haiku poem\",\n",
    "    agent=poet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGreeter\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mCreate a warm greeting for the world\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGreeter\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Hello, world! It is with great enthusiasm and joy that I greet you today. I am overjoyed to connect with all of you, near and far, and to share in the wonder of this moment. Each and every one of you is a precious and valued member of our global community, and I am honored to welcome you with open arms. \n",
      "\n",
      "May this greeting fill your heart with warmth and your spirit with hope. Let us come together in a spirit of unity, compassion, and celebration of our shared humanity. I extend my heartfelt wishes for peace, prosperity, and happiness to all. Hello, world - I am thrilled to greet you!\u001b[00m\n",
      "\n",
      "\n",
      "Task_Callback function called\n",
      "task callback: Hello, world! It is with great enthusiasm and joy that I greet you today. I am overjoyed to connect with all of you, near and far, and to share in the wonder of this moment. Each and every one of you is a precious and valued member of our global community, and I am honored to welcome you with open arms. \n",
      "\n",
      "May this greeting fill your heart with warmth and your spirit with hope. Let us come together in a spirit of unity, compassion, and celebration of our shared humanity. I extend my heartfelt wishes for peace, prosperity, and happiness to all. Hello, world - I am thrilled to greet you!\n",
      "Crew Result:\n",
      "Hello, world! It is with great enthusiasm and joy that I greet you today. I am overjoyed to connect with all of you, near and far, and to share in the wonder of this moment. Each and every one of you is a precious and valued member of our global community, and I am honored to welcome you with open arms. \n",
      "\n",
      "May this greeting fill your heart with warmth and your spirit with hope. Let us come together in a spirit of unity, compassion, and celebration of our shared humanity. I extend my heartfelt wishes for peace, prosperity, and happiness to all. Hello, world - I am thrilled to greet you!\n"
     ]
    }
   ],
   "source": [
    "# Create the crew\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    verbose=True,\n",
    "    task_callback=task_callback_function,\n",
    "    \n",
    ")\n",
    "# Run the crew\n",
    "result = crew.kickoff()\n",
    "\n",
    "print(\"Crew Result:\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
