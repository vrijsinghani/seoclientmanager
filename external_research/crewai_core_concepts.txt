Agents
What is an Agent?¶
What is an Agent?

An agent is an autonomous unit programmed to:

Perform tasks
Make decisions
Communicate with other agents

Think of an agent as a member of a team, with specific skills and a particular job to do. Agents can have different roles like 'Researcher', 'Writer', or 'Customer Support', each contributing to the overall goal of the crew.
Agent Attributes¶
Attribute	Parameter	Description
Role	role	Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.
Goal	goal	The individual objective that the agent aims to achieve. It guides the agent's decision-making process.
Backstory	backstory	Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.
LLM (optional)	llm	Represents the language model that will run the agent. It dynamically fetches the model name from the OPENAI_MODEL_NAME environment variable, defaulting to "gpt-4" if not specified.
Tools (optional)	tools	Set of capabilities or functions that the agent can use to perform tasks. Expected to be instances of custom classes compatible with the agent's execution environment. Tools are initialized with a default value of an empty list.
Function Calling LLM (optional)	function_calling_llm	Specifies the language model that will handle the tool calling for this agent, overriding the crew function calling LLM if passed. Default is None.
Max Iter (optional)	max_iter	Max Iter is the maximum number of iterations the agent can perform before being forced to give its best answer. Default is 25.
Max RPM (optional)	max_rpm	Max RPM is the maximum number of requests per minute the agent can perform to avoid rate limits. It's optional and can be left unspecified, with a default value of None.
Max Execution Time (optional)	max_execution_time	Max Execution Time is the maximum execution time for an agent to execute a task. It's optional and can be left unspecified, with a default value of None, meaning no max execution time.
Verbose (optional)	verbose	Setting this to True configures the internal logger to provide detailed execution logs, aiding in debugging and monitoring. Default is False.
Allow Delegation (optional)	allow_delegation	Agents can delegate tasks or questions to one another, ensuring that each task is handled by the most suitable agent. Default is False.
Step Callback (optional)	step_callback	A function that is called after each step of the agent. This can be used to log the agent's actions or to perform other operations. It will overwrite the crew step_callback.
Cache (optional)	cache	Indicates if the agent should use a cache for tool usage. Default is True.
System Template (optional)	system_template	Specifies the system format for the agent. Default is None.
Prompt Template (optional)	prompt_template	Specifies the prompt format for the agent. Default is None.
Response Template (optional)	response_template	Specifies the response format for the agent. Default is None.
Allow Code Execution (optional)	allow_code_execution	Enable code execution for the agent. Default is False.
Max Retry Limit (optional)	max_retry_limit	Maximum number of retries for an agent to execute a task when an error occurs. Default is 2.
Use System Prompt (optional)	use_system_prompt	Adds the ability to not use system prompt (to support o1 models). Default is True.
Respect Context Window (optional)	respect_context_window	Summary strategy to avoid overflowing the context window. Default is True.
Creating an Agent¶
Agent Interaction

Agents can interact with each other using crewAI's built-in delegation and communication mechanisms. This allows for dynamic task management and problem-solving within the crew.

To create an agent, you would typically initialize an instance of the Agent class with the desired properties. Here's a conceptual example including all attributes:


# Example: Creating an agent with all attributes
from crewai import Agent

agent = Agent(
  role='Data Analyst',
  goal='Extract actionable insights',
  backstory="""You're a data analyst at a large company.
  You're responsible for analyzing data and providing insights
  to the business.
  You're currently working on a project to analyze the
  performance of our marketing campaigns.""",
  tools=[my_tool1, my_tool2],  # Optional, defaults to an empty list
  llm=my_llm,  # Optional
  function_calling_llm=my_llm,  # Optional
  max_iter=15,  # Optional
  max_rpm=None, # Optional
  max_execution_time=None, # Optional
  verbose=True,  # Optional
  allow_delegation=False,  # Optional
  step_callback=my_intermediate_step_callback,  # Optional
  cache=True,  # Optional
  system_template=my_system_template,  # Optional
  prompt_template=my_prompt_template,  # Optional
  response_template=my_response_template,  # Optional
  config=my_config,  # Optional
  crew=my_crew,  # Optional
  tools_handler=my_tools_handler,  # Optional
  cache_handler=my_cache_handler,  # Optional
  callbacks=[callback1, callback2],  # Optional
  allow_code_execution=True,  # Optional
  max_retry_limit=2,  # Optional
  use_system_prompt=True,  # Optional
  respect_context_window=True,  # Optional
)
Setting prompt templates¶
Prompt templates are used to format the prompt for the agent. You can use to update the system, regular and response templates for the agent. Here's an example of how to set prompt templates:


agent = Agent(
        role="{topic} specialist",
        goal="Figure {goal} out",
        backstory="I am the master of {role}",
        system_template="""<|start_header_id|>system<|end_header_id|>

{{ .System }}<|eot_id|>""",
        prompt_template="""<|start_header_id|>user<|end_header_id|>

{{ .Prompt }}<|eot_id|>""",
        response_template="""<|start_header_id|>assistant<|end_header_id|>

{{ .Response }}<|eot_id|>""",
    )
Bring your Third Party Agents¶
Extend your Third Party Agents like LlamaIndex, Langchain, Autogen or fully custom agents using the the crewai's BaseAgent class.

BaseAgent includes attributes and methods required to integrate with your crews to run and delegate tasks to other agents within your own crew.

CrewAI is a universal multi-agent framework that allows for all agents to work together to automate tasks and solve problems.


from crewai import Agent, Task, Crew
from custom_agent import CustomAgent # You need to build and extend your own agent logic with the CrewAI BaseAgent class then import it here.

from langchain.agents import load_tools

langchain_tools = load_tools(["google-serper"], llm=llm)

agent1 = CustomAgent(
    role="agent role",
    goal="who is {input}?",
    backstory="agent backstory",
    verbose=True,
)

task1 = Task(
    expected_output="a short biography of {input}",
    description="a short biography of {input}",
    agent=agent1,
)

agent2 = Agent(
    role="agent role",
    goal="summarize the short bio for {input} and if needed do more research",
    backstory="agent backstory",
    verbose=True,
)

task2 = Task(
    description="a tldr summary of the short biography",
    expected_output="5 bullet point summary of the biography",
    agent=agent2,
    context=[task1],
)

my_crew = Crew(agents=[agent1, agent2], tasks=[task1, task2])
crew = my_crew.kickoff(inputs={"input": "Mark Twain"})
Conclusion¶
Agents are the building blocks of the CrewAI framework. By understanding how to define and interact with agents, you can create sophisticated AI systems that leverage the power of collaborative intelligence.

Tasks
Overview of a Task¶
What is a Task?

In the crewAI framework, tasks are specific assignments completed by agents. They provide all necessary details for execution, such as a description, the agent responsible, required tools, and more, facilitating a wide range of action complexities.

Tasks within crewAI can be collaborative, requiring multiple agents to work together. This is managed through the task properties and orchestrated by the Crew's process, enhancing teamwork and efficiency.

Task Attributes¶
Attribute	Parameters	Type	Description
Description	description	str	A clear, concise statement of what the task entails.
Agent	agent	Optional[BaseAgent]	The agent responsible for the task, assigned either directly or by the crew's process.
Expected Output	expected_output	str	A detailed description of what the task's completion looks like.
Tools (optional)	tools	Optional[List[Any]]	The functions or capabilities the agent can utilize to perform the task. Defaults to an empty list.
Async Execution (optional)	async_execution	Optional[bool]	If set, the task executes asynchronously, allowing progression without waiting for completion. Defaults to False.
Context (optional)	context	Optional[List["Task"]]	Specifies tasks whose outputs are used as context for this task.
Config (optional)	config	Optional[Dict[str, Any]]	Additional configuration details for the agent executing the task, allowing further customization. Defaults to None.
Output JSON (optional)	output_json	Optional[Type[BaseModel]]	Outputs a JSON object, requiring an OpenAI client. Only one output format can be set.
Output Pydantic (optional)	output_pydantic	Optional[Type[BaseModel]]	Outputs a Pydantic model object, requiring an OpenAI client. Only one output format can be set.
Output File (optional)	output_file	Optional[str]	Saves the task output to a file. If used with Output JSON or Output Pydantic, specifies how the output is saved.
Output (optional)	output	Optional[TaskOutput]	An instance of TaskOutput, containing the raw, JSON, and Pydantic output plus additional details.
Callback (optional)	callback	Optional[Any]	A callable that is executed with the task's output upon completion.
Human Input (optional)	human_input	Optional[bool]	Indicates if the task should involve human review at the end, useful for tasks needing human oversight. Defaults to False.
Converter Class (optional)	converter_cls	Optional[Type[Converter]]	A converter class used to export structured output. Defaults to None.
Creating a Task¶
Creating a task involves defining its scope, responsible agent, and any additional attributes for flexibility:


from crewai import Task

task = Task(
    description='Find and summarize the latest and most relevant news on AI',
    agent=sales_agent,
    expected_output='A bullet list summary of the top 5 most important AI news',
)
Task Assignment

Directly specify an agent for assignment or let the hierarchical CrewAI's process decide based on roles, availability, etc.

Task Output¶
Understanding Task Outputs

The output of a task in the crewAI framework is encapsulated within the TaskOutput class. This class provides a structured way to access results of a task, including various formats such as raw output, JSON, and Pydantic models. By default, the TaskOutput will only include the raw output. A TaskOutput will only include the pydantic or json_dict output if the original Task object was configured with output_pydantic or output_json, respectively.

Task Output Attributes¶
Attribute	Parameters	Type	Description
Description	description	str	Description of the task.
Summary	summary	Optional[str]	Summary of the task, auto-generated from the first 10 words of the description.
Raw	raw	str	The raw output of the task. This is the default format for the output.
Pydantic	pydantic	Optional[BaseModel]	A Pydantic model object representing the structured output of the task.
JSON Dict	json_dict	Optional[Dict[str, Any]]	A dictionary representing the JSON output of the task.
Agent	agent	str	The agent that executed the task.
Output Format	output_format	OutputFormat	The format of the task output, with options including RAW, JSON, and Pydantic. The default is RAW.
Task Methods and Properties¶
Method/Property	Description
json	Returns the JSON string representation of the task output if the output format is JSON.
to_dict	Converts the JSON and Pydantic outputs to a dictionary.
str	Returns the string representation of the task output, prioritizing Pydantic, then JSON, then raw.
Accessing Task Outputs¶
Once a task has been executed, its output can be accessed through the output attribute of the Task object. The TaskOutput class provides various ways to interact with and present this output.

Example¶

# Example task
task = Task(
    description='Find and summarize the latest AI news',
    expected_output='A bullet list summary of the top 5 most important AI news',
    agent=research_agent,
    tools=[search_tool]
)

# Execute the crew
crew = Crew(
    agents=[research_agent],
    tasks=[task],
    verbose=True
)

result = crew.kickoff()

# Accessing the task output
task_output = task.output

print(f"Task Description: {task_output.description}")
print(f"Task Summary: {task_output.summary}")
print(f"Raw Output: {task_output.raw}")
if task_output.json_dict:
    print(f"JSON Output: {json.dumps(task_output.json_dict, indent=2)}")
if task_output.pydantic:
    print(f"Pydantic Output: {task_output.pydantic}")
Integrating Tools with Tasks¶
Leverage tools from the crewAI Toolkit and LangChain Tools for enhanced task performance and agent interaction.

Creating a Task with Tools¶

import os
os.environ["OPENAI_API_KEY"] = "Your Key"
os.environ["SERPER_API_KEY"] = "Your Key" # serper.dev API key

from crewai import Agent, Task, Crew
from crewai_tools import SerperDevTool

research_agent = Agent(
  role='Researcher',
  goal='Find and summarize the latest AI news',
  backstory="""You're a researcher at a large company.
  You're responsible for analyzing data and providing insights
  to the business.""",
  verbose=True
)

# to perform a semantic search for a specified query from a text's content across the internet
search_tool = SerperDevTool()

task = Task(
  description='Find and summarize the latest AI news',
  expected_output='A bullet list summary of the top 5 most important AI news',
  agent=research_agent,
  tools=[search_tool]
)

crew = Crew(
    agents=[research_agent],
    tasks=[task],
    verbose=True
)

result = crew.kickoff()
print(result)
This demonstrates how tasks with specific tools can override an agent's default set for tailored task execution.

Referring to Other Tasks¶
In crewAI, the output of one task is automatically relayed into the next one, but you can specifically define what tasks' output, including multiple, should be used as context for another task.

This is useful when you have a task that depends on the output of another task that is not performed immediately after it. This is done through the context attribute of the task:


# ...

research_ai_task = Task(
    description='Find and summarize the latest AI news',
    expected_output='A bullet list summary of the top 5 most important AI news',
    async_execution=True,
    agent=research_agent,
    tools=[search_tool]
)

research_ops_task = Task(
    description='Find and summarize the latest AI Ops news',
    expected_output='A bullet list summary of the top 5 most important AI Ops news',
    async_execution=True,
    agent=research_agent,
    tools=[search_tool]
)

write_blog_task = Task(
    description="Write a full blog post about the importance of AI and its latest news",
    expected_output='Full blog post that is 4 paragraphs long',
    agent=writer_agent,
    context=[research_ai_task, research_ops_task]
)

#...
Asynchronous Execution¶
You can define a task to be executed asynchronously. This means that the crew will not wait for it to be completed to continue with the next task. This is useful for tasks that take a long time to be completed, or that are not crucial for the next tasks to be performed.

You can then use the context attribute to define in a future task that it should wait for the output of the asynchronous task to be completed.


#...

list_ideas = Task(
    description="List of 5 interesting ideas to explore for an article about AI.",
    expected_output="Bullet point list of 5 ideas for an article.",
    agent=researcher,
    async_execution=True # Will be executed asynchronously
)

list_important_history = Task(
    description="Research the history of AI and give me the 5 most important events.",
    expected_output="Bullet point list of 5 important events.",
    agent=researcher,
    async_execution=True # Will be executed asynchronously
)

write_article = Task(
    description="Write an article about AI, its history, and interesting ideas.",
    expected_output="A 4 paragraph article about AI.",
    agent=writer,
    context=[list_ideas, list_important_history] # Will wait for the output of the two tasks to be completed
)

#...
Callback Mechanism¶
The callback function is executed after the task is completed, allowing for actions or notifications to be triggered based on the task's outcome.


# ...

def callback_function(output: TaskOutput):
    # Do something after the task is completed
    # Example: Send an email to the manager
    print(f"""
        Task completed!
        Task: {output.description}
        Output: {output.raw}
    """)

research_task = Task(
    description='Find and summarize the latest AI news',
    expected_output='A bullet list summary of the top 5 most important AI news',
    agent=research_agent,
    tools=[search_tool],
    callback=callback_function
)

#...
Accessing a Specific Task Output¶
Once a crew finishes running, you can access the output of a specific task by using the output attribute of the task object:


# ...
task1 = Task(
    description='Find and summarize the latest AI news',
    expected_output='A bullet list summary of the top 5 most important AI news',
    agent=research_agent,
    tools=[search_tool]
)

#...

crew = Crew(
    agents=[research_agent],
    tasks=[task1, task2, task3],
    verbose=True
)

result = crew.kickoff()

# Returns a TaskOutput object with the description and results of the task
print(f"""
    Task completed!
    Task: {task1.output.description}
    Output: {task1.output.raw}
""")
Tool Override Mechanism¶
Specifying tools in a task allows for dynamic adaptation of agent capabilities, emphasizing CrewAI's flexibility.

Error Handling and Validation Mechanisms¶
While creating and executing tasks, certain validation mechanisms are in place to ensure the robustness and reliability of task attributes. These include but are not limited to:

Ensuring only one output type is set per task to maintain clear output expectations.
Preventing the manual assignment of the id attribute to uphold the integrity of the unique identifier system.
These validations help in maintaining the consistency and reliability of task executions within the crewAI framework.

Creating Directories when Saving Files¶
You can now specify if a task should create directories when saving its output to a file. This is particularly useful for organizing outputs and ensuring that file paths are correctly structured.


# ...

save_output_task = Task(
    description='Save the summarized AI news to a file',
    expected_output='File saved successfully',
    agent=research_agent,
    tools=[file_save_tool],
    output_file='outputs/ai_news_summary.txt',
    create_directory=True
)

#...
Conclusion¶
Tasks are the driving force behind the actions of agents in crewAI. By properly defining tasks and their outcomes, you set the stage for your AI agents to work effectively, either independently or as a collaborative unit. Equipping tasks with appropriate tools, understanding the execution process, and following robust validation practices are crucial for maximizing CrewAI's potential, ensuring agents are effectively prepared for their assignments and that tasks are executed as intended.

Tools
Introduction¶
CrewAI tools empower agents with capabilities ranging from web searching and data analysis to collaboration and delegating tasks among coworkers. This documentation outlines how to create, integrate, and leverage these tools within the CrewAI framework, including a new focus on collaboration tools.

What is a Tool?¶
Definition

A tool in CrewAI is a skill or function that agents can utilize to perform various actions. This includes tools from the crewAI Toolkit and LangChain Tools, enabling everything from simple searches to complex interactions and effective teamwork among agents.

Key Characteristics of Tools¶
Utility: Crafted for tasks such as web searching, data analysis, content generation, and agent collaboration.
Integration: Boosts agent capabilities by seamlessly integrating tools into their workflow.
Customizability: Provides the flexibility to develop custom tools or utilize existing ones, catering to the specific needs of agents.
Error Handling: Incorporates robust error handling mechanisms to ensure smooth operation.
Caching Mechanism: Features intelligent caching to optimize performance and reduce redundant operations.
Using crewAI Tools¶
To enhance your agents' capabilities with crewAI tools, begin by installing our extra tools package:


pip install 'crewai[tools]'
Here's an example demonstrating their use:


import os
from crewai import Agent, Task, Crew
# Importing crewAI tools
from crewai_tools import (
    DirectoryReadTool,
    FileReadTool,
    SerperDevTool,
    WebsiteSearchTool
)

# Set up API keys
os.environ["SERPER_API_KEY"] = "Your Key" # serper.dev API key
os.environ["OPENAI_API_KEY"] = "Your Key"

# Instantiate tools
docs_tool = DirectoryReadTool(directory='./blog-posts')
file_tool = FileReadTool()
search_tool = SerperDevTool()
web_rag_tool = WebsiteSearchTool()

# Create agents
researcher = Agent(
    role='Market Research Analyst',
    goal='Provide up-to-date market analysis of the AI industry',
    backstory='An expert analyst with a keen eye for market trends.',
    tools=[search_tool, web_rag_tool],
    verbose=True
)

writer = Agent(
    role='Content Writer',
    goal='Craft engaging blog posts about the AI industry',
    backstory='A skilled writer with a passion for technology.',
    tools=[docs_tool, file_tool],
    verbose=True
)

# Define tasks
research = Task(
    description='Research the latest trends in the AI industry and provide a summary.',
    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',
    agent=researcher
)

write = Task(
    description='Write an engaging blog post about the AI industry, based on the research analyst’s summary. Draw inspiration from the latest blog posts in the directory.',
    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',
    agent=writer,
    output_file='blog-posts/new_post.md'  # The final blog post will be saved here
)

# Assemble a crew with planning enabled
crew = Crew(
    agents=[researcher, writer],
    tasks=[research, write],
    verbose=True,
    planning=True,  # Enable planning feature
)

# Execute tasks
crew.kickoff()
Available crewAI Tools¶
Error Handling: All tools are built with error handling capabilities, allowing agents to gracefully manage exceptions and continue their tasks.
Caching Mechanism: All tools support caching, enabling agents to efficiently reuse previously obtained results, reducing the load on external resources and speeding up the execution time. You can also define finer control over the caching mechanism using the cache_function attribute on the tool.
Here is a list of the available tools and their descriptions:

Tool	Description
BrowserbaseLoadTool	A tool for interacting with and extracting data from web browsers.
CodeDocsSearchTool	A RAG tool optimized for searching through code documentation and related technical documents.
CodeInterpreterTool	A tool for interpreting python code.
ComposioTool	Enables use of Composio tools.
CSVSearchTool	A RAG tool designed for searching within CSV files, tailored to handle structured data.
DALL-E Tool	A tool for generating images using the DALL-E API.
DirectorySearchTool	A RAG tool for searching within directories, useful for navigating through file systems.
DOCXSearchTool	A RAG tool aimed at searching within DOCX documents, ideal for processing Word files.
DirectoryReadTool	Facilitates reading and processing of directory structures and their contents.
EXASearchTool	A tool designed for performing exhaustive searches across various data sources.
FileReadTool	Enables reading and extracting data from files, supporting various file formats.
FirecrawlSearchTool	A tool to search webpages using Firecrawl and return the results.
FirecrawlCrawlWebsiteTool	A tool for crawling webpages using Firecrawl.
FirecrawlScrapeWebsiteTool	A tool for scraping webpages URL using Firecrawl and returning its contents.
GithubSearchTool	A RAG tool for searching within GitHub repositories, useful for code and documentation search.
SerperDevTool	A specialized tool for development purposes, with specific functionalities under development.
TXTSearchTool	A RAG tool focused on searching within text (.txt) files, suitable for unstructured data.
JSONSearchTool	A RAG tool designed for searching within JSON files, catering to structured data handling.
LlamaIndexTool	Enables the use of LlamaIndex tools.
MDXSearchTool	A RAG tool tailored for searching within Markdown (MDX) files, useful for documentation.
PDFSearchTool	A RAG tool aimed at searching within PDF documents, ideal for processing scanned documents.
PGSearchTool	A RAG tool optimized for searching within PostgreSQL databases, suitable for database queries.
Vision Tool	A tool for generating images using the DALL-E API.
RagTool	A general-purpose RAG tool capable of handling various data sources and types.
ScrapeElementFromWebsiteTool	Enables scraping specific elements from websites, useful for targeted data extraction.
ScrapeWebsiteTool	Facilitates scraping entire websites, ideal for comprehensive data collection.
WebsiteSearchTool	A RAG tool for searching website content, optimized for web data extraction.
XMLSearchTool	A RAG tool designed for searching within XML files, suitable for structured data formats.
YoutubeChannelSearchTool	A RAG tool for searching within YouTube channels, useful for video content analysis.
YoutubeVideoSearchTool	A RAG tool aimed at searching within YouTube videos, ideal for video data extraction.
Creating your own Tools¶
Custom Tool Creation

Developers can craft custom tools tailored for their agent’s needs or utilize pre-built options:

To create your own crewAI tools you will need to install our extra tools package:


pip install 'crewai[tools]'
Once you do that there are two main ways for one to create a crewAI tool:

Subclassing BaseTool¶

from crewai_tools import BaseTool

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "Clear description for what this tool is useful for, your agent will need this information to use it."

    def _run(self, argument: str) -> str:
        # Implementation goes here
        return "Result from custom tool"
Utilizing the tool Decorator¶

from crewai_tools import tool
@tool("Name of my tool")
def my_tool(question: str) -> str:
    """Clear description for what this tool is useful for, your agent will need this information to use it."""
    # Function logic here
    return "Result from your custom tool"
Custom Caching Mechanism¶
Caching

Tools can optionally implement a cache_function to fine-tune caching behavior. This function determines when to cache results based on specific conditions, offering granular control over caching logic.


from crewai_tools import tool

@tool
def multiplication_tool(first_number: int, second_number: int) -> str:
    """Useful for when you need to multiply two numbers together."""
    return first_number * second_number

def cache_func(args, result):
    # In this case, we only cache the result if it's a multiple of 2
    cache = result % 2 == 0
    return cache

multiplication_tool.cache_function = cache_func

writer1 = Agent(
        role="Writer",
        goal="You write lessons of math for kids.",
        backstory="You're an expert in writing and you love to teach kids but you know nothing of math.",
        tools=[multiplication_tool],
        allow_delegation=False,
    )
    #...
Conclusion¶
Tools are pivotal in extending the capabilities of CrewAI agents, enabling them to undertake a broad spectrum of tasks and collaborate effectively. When building solutions with CrewAI, leverage both custom and existing tools to empower your agents and enhance the AI ecosystem. Consider utilizing error handling, caching mechanisms, and the flexibility of tool arguments to optimize your agents' performance and capabilities.

Processes
Understanding Processes¶
Core Concept

In CrewAI, processes orchestrate the execution of tasks by agents, akin to project management in human teams. These processes ensure tasks are distributed and executed efficiently, in alignment with a predefined strategy.

Process Implementations¶
Sequential: Executes tasks sequentially, ensuring tasks are completed in an orderly progression.
Hierarchical: Organizes tasks in a managerial hierarchy, where tasks are delegated and executed based on a structured chain of command. A manager language model (manager_llm) or a custom manager agent (manager_agent) must be specified in the crew to enable the hierarchical process, facilitating the creation and management of tasks by the manager.
Consensual Process (Planned): Aiming for collaborative decision-making among agents on task execution, this process type introduces a democratic approach to task management within CrewAI. It is planned for future development and is not currently implemented in the codebase.
The Role of Processes in Teamwork¶
Processes enable individual agents to operate as a cohesive unit, streamlining their efforts to achieve common objectives with efficiency and coherence.

Assigning Processes to a Crew¶
To assign a process to a crew, specify the process type upon crew creation to set the execution strategy. For a hierarchical process, ensure to define manager_llm or manager_agent for the manager agent.


from crewai import Crew
from crewai.process import Process
from langchain_openai import ChatOpenAI

# Example: Creating a crew with a sequential process
crew = Crew(
    agents=my_agents,
    tasks=my_tasks,
    process=Process.sequential
)

# Example: Creating a crew with a hierarchical process
# Ensure to provide a manager_llm or manager_agent
crew = Crew(
    agents=my_agents,
    tasks=my_tasks,
    process=Process.hierarchical,
    manager_llm=ChatOpenAI(model="gpt-4")
    # or
    # manager_agent=my_manager_agent
)
Note: Ensure my_agents and my_tasks are defined prior to creating a Crew object, and for the hierarchical process, either manager_llm or manager_agent is also required.
Sequential Process¶
This method mirrors dynamic team workflows, progressing through tasks in a thoughtful and systematic manner. Task execution follows the predefined order in the task list, with the output of one task serving as context for the next.

To customize task context, utilize the context parameter in the Task class to specify outputs that should be used as context for subsequent tasks.

Hierarchical Process¶
Emulates a corporate hierarchy, CrewAI allows specifying a custom manager agent or automatically creates one, requiring the specification of a manager language model (manager_llm). This agent oversees task execution, including planning, delegation, and validation. Tasks are not pre-assigned; the manager allocates tasks to agents based on their capabilities, reviews outputs, and assesses task completion.

Process Class: Detailed Overview¶
The Process class is implemented as an enumeration (Enum), ensuring type safety and restricting process values to the defined types (sequential, hierarchical). The consensual process is planned for future inclusion, emphasizing our commitment to continuous development and innovation.

Conclusion¶
The structured collaboration facilitated by processes within CrewAI is crucial for enabling systematic teamwork among agents. This documentation has been updated to reflect the latest features, enhancements, and the planned integration of the Consensual Process, ensuring users have access to the most current and comprehensive information.

Crews
What is a Crew?¶
A crew in crewAI represents a collaborative group of agents working together to achieve a set of tasks. Each crew defines the strategy for task execution, agent collaboration, and the overall workflow.

Crew Attributes¶
Attribute	Parameters	Description
Tasks	tasks	A list of tasks assigned to the crew.
Agents	agents	A list of agents that are part of the crew.
Process (optional)	process	The process flow (e.g., sequential, hierarchical) the crew follows. Default is sequential.
Verbose (optional)	verbose	The verbosity level for logging during execution. Defaults to False.
Manager LLM (optional)	manager_llm	The language model used by the manager agent in a hierarchical process. Required when using a hierarchical process.
Function Calling LLM (optional)	function_calling_llm	If passed, the crew will use this LLM to do function calling for tools for all agents in the crew. Each agent can have its own LLM, which overrides the crew's LLM for function calling.
Config (optional)	config	Optional configuration settings for the crew, in Json or Dict[str, Any] format.
Max RPM (optional)	max_rpm	Maximum requests per minute the crew adheres to during execution. Defaults to None.
Language (optional)	language	Language used for the crew, defaults to English.
Language File (optional)	language_file	Path to the language file to be used for the crew.
Memory (optional)	memory	Utilized for storing execution memories (short-term, long-term, entity memory). Defaults to False.
Cache (optional)	cache	Specifies whether to use a cache for storing the results of tools' execution. Defaults to True.
Embedder (optional)	embedder	Configuration for the embedder to be used by the crew. Mostly used by memory for now. Default is {"provider": "openai"}.
Full Output (optional)	full_output	Whether the crew should return the full output with all tasks outputs or just the final output. Defaults to False.
Step Callback (optional)	step_callback	A function that is called after each step of every agent. This can be used to log the agent's actions or to perform other operations; it won't override the agent-specific step_callback.
Task Callback (optional)	task_callback	A function that is called after the completion of each task. Useful for monitoring or additional operations post-task execution.
Share Crew (optional)	share_crew	Whether you want to share the complete crew information and execution with the crewAI team to make the library better, and allow us to train models.
Output Log File (optional)	output_log_file	Whether you want to have a file with the complete crew output and execution. You can set it using True and it will default to the folder you are currently in and it will be called logs.txt or passing a string with the full path and name of the file.
Manager Agent (optional)	manager_agent	manager sets a custom agent that will be used as a manager.
Manager Callbacks (optional)	manager_callbacks	manager_callbacks takes a list of callback handlers to be executed by the manager agent when a hierarchical process is used.
Prompt File (optional)	prompt_file	Path to the prompt JSON file to be used for the crew.
Planning (optional)	planning	Adds planning ability to the Crew. When activated before each Crew iteration, all Crew data is sent to an AgentPlanner that will plan the tasks and this plan will be added to each task description.
Planning LLM (optional)	planning_llm	The language model used by the AgentPlanner in a planning process.
Crew Max RPM

The max_rpm attribute sets the maximum number of requests per minute the crew can perform to avoid rate limits and will override individual agents' max_rpm settings if you set it.

Crew Output¶
Understanding Crew Outputs

The output of a crew in the crewAI framework is encapsulated within the CrewOutput class. This class provides a structured way to access results of the crew's execution, including various formats such as raw strings, JSON, and Pydantic models. The CrewOutput includes the results from the final task output, token usage, and individual task outputs.

Crew Output Attributes¶
Attribute	Parameters	Type	Description
Raw	raw	str	The raw output of the crew. This is the default format for the output.
Pydantic	pydantic	Optional[BaseModel]	A Pydantic model object representing the structured output of the crew.
JSON Dict	json_dict	Optional[Dict[str, Any]]	A dictionary representing the JSON output of the crew.
Tasks Output	tasks_output	List[TaskOutput]	A list of TaskOutput objects, each representing the output of a task in the crew.
Token Usage	token_usage	Dict[str, Any]	A summary of token usage, providing insights into the language model's performance during execution.
Crew Output Methods and Properties¶
Method/Property	Description
json	Returns the JSON string representation of the crew output if the output format is JSON.
to_dict	Converts the JSON and Pydantic outputs to a dictionary.
**str**	Returns the string representation of the crew output, prioritizing Pydantic, then JSON, then raw.
Accessing Crew Outputs¶
Once a crew has been executed, its output can be accessed through the output attribute of the Crew object. The CrewOutput class provides various ways to interact with and present this output.

Example¶

# Example crew execution
crew = Crew(
    agents=[research_agent, writer_agent],
    tasks=[research_task, write_article_task],
    verbose=True
)

crew_output = crew.kickoff()

# Accessing the crew output
print(f"Raw Output: {crew_output.raw}")
if crew_output.json_dict:
    print(f"JSON Output: {json.dumps(crew_output.json_dict, indent=2)}")
if crew_output.pydantic:
    print(f"Pydantic Output: {crew_output.pydantic}")
print(f"Tasks Output: {crew_output.tasks_output}")
print(f"Token Usage: {crew_output.token_usage}")
Memory Utilization¶
Crews can utilize memory (short-term, long-term, and entity memory) to enhance their execution and learning over time. This feature allows crews to store and recall execution memories, aiding in decision-making and task execution strategies.

Cache Utilization¶
Caches can be employed to store the results of tools' execution, making the process more efficient by reducing the need to re-execute identical tasks.

Crew Usage Metrics¶
After the crew execution, you can access the usage_metrics attribute to view the language model (LLM) usage metrics for all tasks executed by the crew. This provides insights into operational efficiency and areas for improvement.


# Access the crew's usage metrics
crew = Crew(agents=[agent1, agent2], tasks=[task1, task2])
crew.kickoff()
print(crew.usage_metrics)
Crew Execution Process¶
Sequential Process: Tasks are executed one after another, allowing for a linear flow of work.
Hierarchical Process: A manager agent coordinates the crew, delegating tasks and validating outcomes before proceeding. Note: A manager_llm or manager_agent is required for this process and it's essential for validating the process flow.
Kicking Off a Crew¶
Once your crew is assembled, initiate the workflow with the kickoff() method. This starts the execution process according to the defined process flow.


# Start the crew's task execution
result = my_crew.kickoff()
print(result)
Different Ways to Kick Off a Crew¶
Once your crew is assembled, initiate the workflow with the appropriate kickoff method. CrewAI provides several methods for better control over the kickoff process: kickoff(), kickoff_for_each(), kickoff_async(), and kickoff_for_each_async().

kickoff(): Starts the execution process according to the defined process flow.
kickoff_for_each(): Executes tasks for each agent individually.
kickoff_async(): Initiates the workflow asynchronously.
kickoff_for_each_async(): Executes tasks for each agent individually in an asynchronous manner.

# Start the crew's task execution
result = my_crew.kickoff()
print(result)

# Example of using kickoff_for_each
inputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]
results = my_crew.kickoff_for_each(inputs=inputs_array)
for result in results:
    print(result)

# Example of using kickoff_async
inputs = {'topic': 'AI in healthcare'}
async_result = my_crew.kickoff_async(inputs=inputs)
print(async_result)

# Example of using kickoff_for_each_async
inputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]
async_results = my_crew.kickoff_for_each_async(inputs=inputs_array)
for async_result in async_results:
    print(async_result)
These methods provide flexibility in how you manage and execute tasks within your crew, allowing for both synchronous and asynchronous workflows tailored to your needs.

Replaying from a Specific Task¶
You can now replay from a specific task using our CLI command replay.

The replay feature in CrewAI allows you to replay from a specific task using the command-line interface (CLI). By running the command crewai replay -t <task_id>, you can specify the task_id for the replay process.

Kickoffs will now save the latest kickoffs returned task outputs locally for you to be able to replay from.

Replaying from a Specific Task Using the CLI¶
To use the replay feature, follow these steps:

Open your terminal or command prompt.
Navigate to the directory where your CrewAI project is located.
Run the following command:
To view the latest kickoff task IDs, use:


crewai log-tasks-outputs
Then, to replay from a specific task, use:


crewai replay -t <task_id>
These commands let you replay from your latest kickoff tasks, still retaining context from previously executed tasks.

Collaboration
Collaboration Fundamentals¶
Core of Agent Interaction

Collaboration in CrewAI is fundamental, enabling agents to combine their skills, share information, and assist each other in task execution, embodying a truly cooperative ecosystem.

Information Sharing: Ensures all agents are well-informed and can contribute effectively by sharing data and findings.
Task Assistance: Allows agents to seek help from peers with the required expertise for specific tasks.
Resource Allocation: Optimizes task execution through the efficient distribution and sharing of resources among agents.
Enhanced Attributes for Improved Collaboration¶
The Crew class has been enriched with several attributes to support advanced functionalities:

Language Model Management (manager_llm, function_calling_llm): Manages language models for executing tasks and tools, facilitating sophisticated agent-tool interactions. Note that while manager_llm is mandatory for hierarchical processes to ensure proper execution flow, function_calling_llm is optional, with a default value provided for streamlined tool interaction.
Custom Manager Agent (manager_agent): Allows specifying a custom agent as the manager instead of using the default manager provided by CrewAI.
Process Flow (process): Defines the execution logic (e.g., sequential, hierarchical) to streamline task distribution and execution.
Verbose Logging (verbose): Offers detailed logging capabilities for monitoring and debugging purposes. It supports both integer and boolean types to indicate the verbosity level. For example, setting verbose to 1 might enable basic logging, whereas setting it to True enables more detailed logs.
Rate Limiting (max_rpm): Ensures efficient utilization of resources by limiting requests per minute. Guidelines for setting max_rpm should consider the complexity of tasks and the expected load on resources.
Internationalization / Customization Support (language, prompt_file): Facilitates full customization of the inner prompts, enhancing global usability. Supported languages and the process for utilizing the prompt_file attribute for customization should be clearly documented. Example of file
Execution and Output Handling (full_output): Distinguishes between full and final outputs for nuanced control over task results. Examples showcasing the difference in outputs can aid in understanding the practical implications of this attribute.
Callback and Telemetry (step_callback, task_callback): Integrates callbacks for step-wise and task-level execution monitoring, alongside telemetry for performance analytics. The purpose and usage of task_callback alongside step_callback for granular monitoring should be clearly explained.
Crew Sharing (share_crew): Enables sharing of crew information with CrewAI for continuous improvement and training models. The privacy implications and benefits of this feature, including how it contributes to model improvement, should be outlined.
Usage Metrics (usage_metrics): Stores all metrics for the language model (LLM) usage during all tasks' execution, providing insights into operational efficiency and areas for improvement. Detailed information on accessing and interpreting these metrics for performance analysis should be provided.
Memory Usage (memory): Indicates whether the crew should use memory to store memories of its execution, enhancing task execution and agent learning.
Embedder Configuration (embedder): Specifies the configuration for the embedder to be used by the crew for understanding and generating language. This attribute supports customization of the language model provider.
Cache Management (cache): Determines whether the crew should use a cache to store the results of tool executions, optimizing performance.
Output Logging (output_log_file): Specifies the file path for logging the output of the crew's execution.
Planning Mode (planning): Allows crews to plan their actions before executing tasks by setting planning=True when creating the Crew instance. This feature enhances coordination and efficiency.
Replay Feature: Introduces a new CLI for listing tasks from the last run and replaying from a specific task, enhancing task management and troubleshooting.
Delegation: Dividing to Conquer¶
Delegation enhances functionality by allowing agents to intelligently assign tasks or seek help, thereby amplifying the crew's overall capability.

Implementing Collaboration and Delegation¶
Setting up a crew involves defining the roles and capabilities of each agent. CrewAI seamlessly manages their interactions, ensuring efficient collaboration and delegation, with enhanced customization and monitoring features to adapt to various operational needs.

Example Scenario¶
Consider a crew with a researcher agent tasked with data gathering and a writer agent responsible for compiling reports. The integration of advanced language model management and process flow attributes allows for more sophisticated interactions, such as the writer delegating complex research tasks to the researcher or querying specific information, thereby facilitating a seamless workflow.

Conclusion¶
The integration of advanced attributes and functionalities into the CrewAI framework significantly enriches the agent collaboration ecosystem. These enhancements not only simplify interactions but also offer unprecedented flexibility and control, paving the way for sophisticated AI-driven solutions capable of tackling complex tasks through intelligent collaboration and delegation.
Pipeline
What is a Pipeline?¶
A pipeline in crewAI represents a structured workflow that allows for the sequential or parallel execution of multiple crews. It provides a way to organize complex processes involving multiple stages, where the output of one stage can serve as input for subsequent stages.

Key Terminology¶
Understanding the following terms is crucial for working effectively with pipelines:

Stage: A distinct part of the pipeline, which can be either sequential (a single crew) or parallel (multiple crews executing concurrently).
Kickoff: A specific execution of the pipeline for a given set of inputs, representing a single instance of processing through the pipeline.
Branch: Parallel executions within a stage (e.g., concurrent crew operations).
Trace: The journey of an individual input through the entire pipeline, capturing the path and transformations it undergoes.
Example pipeline structure:


crew1 >> [crew2, crew3] >> crew4
This represents a pipeline with three stages:

A sequential stage (crew1)
A parallel stage with two branches (crew2 and crew3 executing concurrently)
Another sequential stage (crew4)
Each input creates its own kickoff, flowing through all stages of the pipeline. Multiple kickoffs can be processed concurrently, each following the defined pipeline structure.

Pipeline Attributes¶
Attribute	Parameters	Description
Stages	stages	A list of PipelineStage (crews, lists of crews, or routers) representing the stages to be executed in sequence.
Creating a Pipeline¶
When creating a pipeline, you define a series of stages, each consisting of either a single crew or a list of crews for parallel execution. The pipeline ensures that each stage is executed in order, with the output of one stage feeding into the next.

Example: Assembling a Pipeline¶

from crewai import Crew, Process, Pipeline

# Define your crews
research_crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    process=Process.sequential
)

analysis_crew = Crew(
    agents=[analyst],
    tasks=[analysis_task],
    process=Process.sequential
)

writing_crew = Crew(
    agents=[writer],
    tasks=[writing_task],
    process=Process.sequential
)

# Assemble the pipeline
my_pipeline = Pipeline(
    stages=[research_crew, analysis_crew, writing_crew]
)
Pipeline Methods¶
Method	Description
kickoff	Executes the pipeline, processing all stages and returning the results. This method initiates one or more kickoffs through the pipeline, handling the flow of data between stages.
process_runs	Runs the pipeline for each input provided, handling the flow and transformation of data between stages.
Pipeline Output¶
Understanding Pipeline Outputs

The output of a pipeline in the crewAI framework is encapsulated within the PipelineKickoffResult class. This class provides a structured way to access the results of the pipeline's execution, including various formats such as raw strings, JSON, and Pydantic models.

Pipeline Output Attributes¶
Attribute	Parameters	Type	Description
ID	id	UUID4	A unique identifier for the pipeline output.
Run Results	run_results	List[PipelineRunResult]	A list of PipelineRunResult objects, each representing the output of a single run through the pipeline.
Pipeline Output Methods¶
Method/Property	Description
add_run_result	Adds a PipelineRunResult to the list of run results.
Pipeline Run Result Attributes¶
Attribute	Parameters	Type	Description
ID	id	UUID4	A unique identifier for the run result.
Raw	raw	str	The raw output of the final stage in the pipeline kickoff.
Pydantic	pydantic	Any	A Pydantic model object representing the structured output of the final stage, if applicable.
JSON Dict	json_dict	Union[Dict[str, Any], None]	A dictionary representing the JSON output of the final stage, if applicable.
Token Usage	token_usage	Dict[str, UsageMetrics]	A summary of token usage across all stages of the pipeline kickoff.
Trace	trace	List[Any]	A trace of the journey of inputs through the pipeline kickoff.
Crews Outputs	crews_outputs	List[CrewOutput]	A list of CrewOutput objects, representing the outputs from each crew in the pipeline kickoff.
Pipeline Run Result Methods and Properties¶
Method/Property	Description
json	Returns the JSON string representation of the run result if the output format of the final task is JSON.
to_dict	Converts the JSON and Pydantic outputs to a dictionary.
str	Returns the string representation of the run result, prioritizing Pydantic, then JSON, then raw.
Accessing Pipeline Outputs¶
Once a pipeline has been executed, its output can be accessed through the PipelineOutput object returned by the process_runs method. The PipelineOutput class provides access to individual PipelineRunResult objects, each representing a single run through the pipeline.

Example¶

# Define input data for the pipeline
input_data = [{"initial_query": "Latest advancements in AI"}, {"initial_query": "Future of robotics"}]

# Execute the pipeline
pipeline_output = await my_pipeline.process_runs(input_data)

# Access the results
for run_result in pipeline_output.run_results:
    print(f"Run ID: {run_result.id}")
    print(f"Final Raw Output: {run_result.raw}")
    if run_result.json_dict:
        print(f"JSON Output: {json.dumps(run_result.json_dict, indent=2)}")
    if run_result.pydantic:
        print(f"Pydantic Output: {run_result.pydantic}")
    print(f"Token Usage: {run_result.token_usage}")
    print(f"Trace: {run_result.trace}")
    print("Crew Outputs:")
    for crew_output in run_result.crews_outputs:
        print(f"  Crew: {crew_output.raw}")
    print("\n")
This example demonstrates how to access and work with the pipeline output, including individual run results and their associated data.

Using Pipelines¶
Pipelines are particularly useful for complex workflows that involve multiple stages of processing, analysis, or content generation. They allow you to:

Sequence Operations: Execute crews in a specific order, ensuring that the output of one crew is available as input to the next.
Parallel Processing: Run multiple crews concurrently within a stage for increased efficiency.
Manage Complex Workflows: Break down large tasks into smaller, manageable steps executed by specialized crews.
Example: Running a Pipeline¶

# Define input data for the pipeline
input_data = [{"initial_query": "Latest advancements in AI"}]

# Execute the pipeline, initiating a run for each input
results = await my_pipeline.process_runs(input_data)

# Access the results
for result in results:
    print(f"Final Output: {result.raw}")
    print(f"Token Usage: {result.token_usage}")
    print(f"Trace: {result.trace}")  # Shows the path of the input through all stages
Advanced Features¶
Parallel Execution within Stages¶
You can define parallel execution within a stage by providing a list of crews, creating multiple branches:


parallel_analysis_crew = Crew(agents=[financial_analyst], tasks=[financial_analysis_task])
market_analysis_crew = Crew(agents=[market_analyst], tasks=[market_analysis_task])

my_pipeline = Pipeline(
    stages=[
        research_crew,
        [parallel_analysis_crew, market_analysis_crew],  # Parallel execution (branching)
        writing_crew
    ]
)
Routers in Pipelines¶
Routers are a powerful feature in crewAI pipelines that allow for dynamic decision-making and branching within your workflow. They enable you to direct the flow of execution based on specific conditions or criteria, making your pipelines more flexible and adaptive.

What is a Router?¶
A router in crewAI is a special component that can be included as a stage in your pipeline. It evaluates the input data and determines which path the execution should take next. This allows for conditional branching in your pipeline, where different crews or sub-pipelines can be executed based on the router's decision.

Key Components of a Router¶
Routes: A dictionary of named routes, each associated with a condition and a pipeline to execute if the condition is met.
Default Route: A fallback pipeline that is executed if none of the defined route conditions are met.
Creating a Router¶
Here's an example of how to create a router:


from crewai import Router, Route, Pipeline, Crew, Agent, Task

# Define your agents
classifier = Agent(name="Classifier", role="Email Classifier")
urgent_handler = Agent(name="Urgent Handler", role="Urgent Email Processor")
normal_handler = Agent(name="Normal Handler", role="Normal Email Processor")

# Define your tasks
classify_task = Task(description="Classify the email based on its content and metadata.")
urgent_task = Task(description="Process and respond to urgent email quickly.")
normal_task = Task(description="Process and respond to normal email thoroughly.")

# Define your crews
classification_crew = Crew(agents=[classifier], tasks=[classify_task]) # classify email between high and low urgency 1-10
urgent_crew = Crew(agents=[urgent_handler], tasks=[urgent_task])
normal_crew = Crew(agents=[normal_handler], tasks=[normal_task])

# Create pipelines for different urgency levels
urgent_pipeline = Pipeline(stages=[urgent_crew])
normal_pipeline = Pipeline(stages=[normal_crew])

# Create a router
email_router = Router(
    routes={
        "high_urgency": Route(
            condition=lambda x: x.get("urgency_score", 0) > 7,
            pipeline=urgent_pipeline
        ),
        "low_urgency": Route(
            condition=lambda x: x.get("urgency_score", 0) <= 7,
            pipeline=normal_pipeline
        )
    },
    default=Pipeline(stages=[normal_pipeline])  # Default to just normal if no urgency score
)

# Use the router in a main pipeline
main_pipeline = Pipeline(stages=[classification_crew, email_router])

inputs = [{"email": "..."}, {"email": "..."}]  # List of email data

main_pipeline.kickoff(inputs=inputs=inputs)
In this example, the router decides between an urgent pipeline and a normal pipeline based on the urgency score of the email. If the urgency score is greater than 7, it routes to the urgent pipeline; otherwise, it uses the normal pipeline. If the input doesn't include an urgency score, it defaults to just the classification crew.

Benefits of Using Routers¶
Dynamic Workflow: Adapt your pipeline's behavior based on input characteristics or intermediate results.
Efficiency: Route urgent tasks to quicker processes, reserving more thorough pipelines for less time-sensitive inputs.
Flexibility: Easily modify or extend your pipeline's logic without changing the core structure.
Scalability: Handle a wide range of email types and urgency levels with a single pipeline structure.
Error Handling and Validation¶
The Pipeline class includes validation mechanisms to ensure the robustness of the pipeline structure:

Validates that stages contain only Crew instances or lists of Crew instances.
Prevents double nesting of stages to maintain a clear structure.

Training
Introduction¶
The training feature in CrewAI allows you to train your AI agents using the command-line interface (CLI). By running the command crewai train -n <n_iterations>, you can specify the number of iterations for the training process.

During training, CrewAI utilizes techniques to optimize the performance of your agents along with human feedback. This helps the agents improve their understanding, decision-making, and problem-solving abilities.

Training Your Crew Using the CLI¶
To use the training feature, follow these steps:

Open your terminal or command prompt.
Navigate to the directory where your CrewAI project is located.
Run the following command:

crewai train -n <n_iterations> <filename> (optional)
Replace <n_iterations> with the desired number of training iterations and <filename> with the appropriate filename ending with .pkl.

Training Your Crew Programmatically¶
To train your crew programmatically, use the following steps:

Define the number of iterations for training.
Specify the input parameters for the training process.
Execute the training command within a try-except block to handle potential errors.

n_iterations = 2
inputs = {"topic": "CrewAI Training"}
filename = "your_model.pkl"

try:
    YourCrewName_Crew().crew().train(n_iterations=n_iterations, inputs=inputs, filename=filename)

except Exception as e:
    raise Exception(f"An error occurred while training the crew: {e}")
Key Points to Note:¶
Positive Integer Requirement: Ensure that the number of iterations (n_iterations) is a positive integer. The code will raise a ValueError if this condition is not met.
Filename Requirement: Ensure that the filename ends with .pkl. The code will raise a ValueError if this condition is not met.
Error Handling: The code handles subprocess errors and unexpected exceptions, providing error messages to the user.
It is important to note that the training process may take some time, depending on the complexity of your agents and will also require your feedback on each iteration.

Once the training is complete, your agents will be equipped with enhanced capabilities and knowledge, ready to tackle complex tasks and provide more consistent and valuable insights.

Remember to regularly update and retrain your agents to ensure they stay up-to-date with the latest information and advancements in the field.

Happy training with CrewAI!
Memory
Introduction to Memory Systems in crewAI¶
Enhancing Agent Intelligence

The crewAI framework introduces a sophisticated memory system designed to significantly enhance the capabilities of AI agents. This system comprises short-term memory, long-term memory, entity memory, and contextual memory, each serving a unique purpose in aiding agents to remember, reason, and learn from past interactions.

Memory System Components¶
Component	Description
Short-Term Memory	Temporarily stores recent interactions and outcomes using RAG, enabling agents to recall and utilize information relevant to their current context during the current executions.
Long-Term Memory	Preserves valuable insights and learnings from past executions, allowing agents to build and refine their knowledge over time.
Entity Memory	Captures and organizes information about entities (people, places, concepts) encountered during tasks, facilitating deeper understanding and relationship mapping. Uses RAG for storing entity information.
Contextual Memory	Maintains the context of interactions by combining ShortTermMemory, LongTermMemory, and EntityMemory, aiding in the coherence and relevance of agent responses over a sequence of tasks or a conversation.
How Memory Systems Empower Agents¶
Contextual Awareness: With short-term and contextual memory, agents gain the ability to maintain context over a conversation or task sequence, leading to more coherent and relevant responses.

Experience Accumulation: Long-term memory allows agents to accumulate experiences, learning from past actions to improve future decision-making and problem-solving.

Entity Understanding: By maintaining entity memory, agents can recognize and remember key entities, enhancing their ability to process and interact with complex information.

Implementing Memory in Your Crew¶
When configuring a crew, you can enable and customize each memory component to suit the crew's objectives and the nature of tasks it will perform. By default, the memory system is disabled, and you can ensure it is active by setting memory=True in the crew configuration. The memory will use OpenAI embeddings by default, but you can change it by setting embedder to a different model. It's also possible to initialize the memory instance with your own instance.

The 'embedder' only applies to Short-Term Memory which uses Chroma for RAG using the EmbedChain package. The Long-Term Memory uses SQLite3 to store task results. Currently, there is no way to override these storage implementations. The data storage files are saved into a platform-specific location found using the appdirs package, and the name of the project can be overridden using the CREWAI_STORAGE_DIR environment variable.

Example: Configuring Memory for a Crew¶

from crewai import Crew, Agent, Task, Process

# Assemble your crew with memory capabilities
my_crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,
    verbose=True
)
Example: Use Custom Memory Instances e.g FAISS as the VectorDB¶

from crewai import Crew, Agent, Task, Process

# Assemble your crew with memory capabilities
my_crew = Crew(
    agents=[...],
    tasks=[...],
    process="Process.sequential",
    memory=True,
    long_term_memory=EnhanceLongTermMemory(
        storage=LTMSQLiteStorage(
            db_path="/my_data_dir/my_crew1/long_term_memory_storage.db"
        )
    ),
    short_term_memory=EnhanceShortTermMemory(
        storage=CustomRAGStorage(
            crew_name="my_crew",
            storage_type="short_term",
            data_dir="//my_data_dir",
            model=embedder["model"],
            dimension=embedder["dimension"],
        ),
    ),
    entity_memory=EnhanceEntityMemory(
        storage=CustomRAGStorage(
            crew_name="my_crew",
            storage_type="entities",
            data_dir="//my_data_dir",
            model=embedder["model"],
            dimension=embedder["dimension"],
        ),
    ),
    verbose=True,
)
Additional Embedding Providers¶
Using OpenAI embeddings (already default)¶

from crewai import Crew, Agent, Task, Process

my_crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,
    verbose=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": 'text-embedding-3-small'
        }
    }
)
Using Google AI embeddings¶

from crewai import Crew, Agent, Task, Process

my_crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,
    verbose=True,
    embedder={
        "provider": "google",
        "config": {
            "model": 'models/embedding-001',
            "task_type": "retrieval_document",
            "title": "Embeddings for Embedchain"
        }
    }
)
Using Azure OpenAI embeddings¶

from crewai import Crew, Agent, Task, Process

my_crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,
    verbose=True,
    embedder={
        "provider": "azure_openai",
        "config": {
            "model": 'text-embedding-ada-002',
            "deployment_name": "your_embedding_model_deployment_name"
        }
    }
)
Using GPT4ALL embeddings¶

from crewai import Crew, Agent, Task, Process

my_crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,
    verbose=True,
    embedder={
        "provider": "gpt4all"
    }
)
Using Vertex AI embeddings¶

from crewai import Crew, Agent, Task, Process

my_crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,
    verbose=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "model": 'textembedding-gecko'
        }
    }
)
Using Cohere embeddings¶

from crewai import Crew, Agent, Task, Process

my_crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,
    verbose=True,
    embedder={
        "provider": "cohere",
        "config": {
            "model": "embed-english-v3.0",
            "vector_dimension": 1024
        }
    }
)
Resetting Memory¶

crewai reset_memories [OPTIONS]
Resetting Memory Options¶
-l, --long
Description: Reset LONG TERM memory.
Type: Flag (boolean)
Default: False

-s, --short

Description: Reset SHORT TERM memory.
Type: Flag (boolean)
Default: False

-e, --entities

Description: Reset ENTITIES memory.
Type: Flag (boolean)
Default: False

-k, --kickoff-outputs

Description: Reset LATEST KICKOFF TASK OUTPUTS.
Type: Flag (boolean)
Default: False

-a, --all

Description: Reset ALL memories.
Type: Flag (boolean)
Default: False
Benefits of Using crewAI's Memory System¶
Adaptive Learning: Crews become more efficient over time, adapting to new information and refining their approach to tasks.
Enhanced Personalization: Memory enables agents to remember user preferences and historical interactions, leading to personalized experiences.
Improved Problem Solving: Access to a rich memory store aids agents in making more informed decisions, drawing on past learnings and contextual insights.
Getting Started¶
Integrating crewAI's memory system into your projects is straightforward. By leveraging the provided memory components and configurations, you can quickly empower your agents with the ability to remember, reason, and learn from their interactions, unlocking new levels of intelligence and capability.
Planning
Introduction¶
The planning feature in CrewAI allows you to add planning capability to your crew. When enabled, before each Crew iteration, all Crew information is sent to an AgentPlanner that will plan the tasks step by step, and this plan will be added to each task description.

Using the Planning Feature¶
Getting started with the planning feature is very easy, the only step required is to add planning=True to your Crew:


from crewai import Crew, Agent, Task, Process

# Assemble your crew with planning capabilities
my_crew = Crew(
    agents=self.agents,
    tasks=self.tasks,
    process=Process.sequential,
    planning=True,
)
From this point on, your crew will have planning enabled, and the tasks will be planned before each iteration.

Planning LLM¶
Now you can define the LLM that will be used to plan the tasks. You can use any ChatOpenAI LLM model available.


from crewai import Crew, Agent, Task, Process
from langchain_openai import ChatOpenAI

# Assemble your crew with planning capabilities and custom LLM
my_crew = Crew(
    agents=self.agents,
    tasks=self.tasks,
    process=Process.sequential,
    planning=True,
    planning_llm=ChatOpenAI(model="gpt-4o")
)
Example¶
When running the base case example, you will see something like the following output, which represents the output of the AgentPlanner responsible for creating the step-by-step logic to add to the Agents' tasks.

``` [2024-07-15 16:49:11][INFO]: Planning the crew execution Step-by-Step Plan for Task Execution

Task Number 1: Conduct a thorough research about AI LLMs

Agent: AI LLMs Senior Data Researcher

Agent Goal: Uncover cutting-edge developments in AI LLMs

Task Expected Output: A list with 10 bullet points of the most relevant information about AI LLMs

Task Tools: None specified

Agent Tools: None specified

Step-by-Step Plan:

Define Research Scope:
Determine the specific areas of AI LLMs to focus on, such as advancements in architecture, use cases, ethical considerations, and performance metrics.

Identify Reliable Sources:

List reputable sources for AI research, including academic journals, industry reports, conferences (e.g., NeurIPS, ACL), AI research labs (e.g., OpenAI, Google AI), and online databases (e.g., IEEE Xplore, arXiv).

Collect Data:

Search for the latest papers, articles, and reports published in 2023 and early 2024.
Use keywords like "Large Language Models 2024", "AI LLM advancements", "AI ethics 2024", etc.

Analyze Findings:

Read and summarize the key points from each source.
Highlight new techniques, models, and applications introduced in the past year.

Organize Information:

Categorize the information into relevant topics (e.g., new architectures, ethical implications, real-world applications).
Ensure each bullet point is concise but informative.

Create the List:

Compile the 10 most relevant pieces of information into a bullet point list.
Review the list to ensure clarity and relevance.
Expected Output: A list with 10 bullet points of the most relevant information about AI LLMs.

Task Number 2: Review the context you got and expand each topic into a full section for a report

Agent: AI LLMs Reporting Analyst

Agent Goal: Create detailed reports based on AI LLMs data analysis and research findings

Task Expected Output: A fully fledged report with the main topics, each with a full section of information. Formatted as markdown without '```'

Task Tools: None specified

Agent Tools: None specified

Step-by-Step Plan:

Review the Bullet Points:
Carefully read through the list of 10 bullet points provided by the AI LLMs Senior Data Researcher.

Outline the Report:

Create an outline with each bullet point as a main section heading.
Plan sub-sections under each main heading to cover different aspects of the topic.

Research Further Details:

For each bullet point, conduct additional research if necessary to gather more detailed information.
Look for case studies, examples, and statistical data to support each section.

Write Detailed Sections:

Expand each bullet point into a comprehensive section.
Ensure each section includes an introduction, detailed explanation, examples, and a conclusion.
Use markdown formatting for headings, subheadings, lists, and emphasis.

Review and Edit:

Proofread the report for clarity, coherence, and correctness.
Make sure the report flows logically from one section to the next.
Format the report according to markdown standards.

Finalize the Report:

Ensure the report is complete with all sections expanded and detailed.
Double-check formatting and make any necessary adjustments.
Expected Output: A fully fledged report with the main topics, each with a full section of information. Formatted as markdown without '```'.

Testing
Introduction¶
Testing is a crucial part of the development process, and it is essential to ensure that your crew is performing as expected. With crewAI, you can easily test your crew and evaluate its performance using the built-in testing capabilities.

Using the Testing Feature¶
We added the CLI command crewai test to make it easy to test your crew. This command will run your crew for a specified number of iterations and provide detailed performance metrics. The parameters are n_iterations and model, which are optional and default to 2 and gpt-4o-mini respectively. For now, the only provider available is OpenAI.


crewai test
If you want to run more iterations or use a different model, you can specify the parameters like this:


crewai test --n_iterations 5 --model gpt-4o
or using the short forms:


crewai test -n 5 -m gpt-4o
When you run the crewai test command, the crew will be executed for the specified number of iterations, and the performance metrics will be displayed at the end of the run.

A table of scores at the end will show the performance of the crew in terms of the following metrics:


                                                     Tasks Scores
                                                (1-10 Higher is better)
┏━━━━━━━━━━━━━━━━━━━━┯━━━━━━━┯━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Tasks/Crew/Agents  │ Run 1 │ Run 2 │ Avg. Total │ Agents                         │                                 ┃
┠────────────────────┼───────┼───────┼────────────┼────────────────────────────────┼─────────────────────────────────┨
┃ Task 1             │  9.0  │  9.5  │    9.2     │ - Professional Insights        │                                 ┃
┃                    │       │       │            │ Researcher                     │                                 ┃
┃                    │       │       │            │                                │                                 ┃
┃ Task 2             │  9.0  │ 10.0  │    9.5     │ - Company Profile Investigator │                                 ┃
┃                    │       │       │            │                                │                                 ┃
┃ Task 3             │  9.0  │  9.0  │    9.0     │ - Automation Insights          │                                 ┃
┃                    │       │       │            │ Specialist                     │                                 ┃
┃                    │       │       │            │                                │                                 ┃
┃ Task 4             │  9.0  │  9.0  │    9.0     │ - Final Report Compiler        │                                 ┃
┃                    │       │       │            │                                │ - Automation Insights           ┃
┃                    │       │       │            │                                │ Specialist                      ┃
┃ Crew               │ 9.00  │ 9.38  │    9.2     │                                │                                 ┃
┃ Execution Time (s) │  126  │  145  │    135     │                                │                                 ┃
┗━━━━━━━━━━━━━━━━━━━━┷━━━━━━━┷━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
The example above shows the test results for two runs of the crew with two tasks, with the average total score for each task and the crew as a whole.
Using LangChain Tools
Using LangChain Tools¶
LangChain Integration

CrewAI seamlessly integrates with LangChain’s comprehensive list of tools, all of which can be used with crewAI.


import os
from crewai import Agent
from langchain.agents import Tool
from langchain.utilities import GoogleSerperAPIWrapper

# Setup API keys
os.environ["SERPER_API_KEY"] = "Your Key"

search = GoogleSerperAPIWrapper()

# Create and assign the search tool to an agent
serper_tool = Tool(
  name="Intermediate Answer",
  func=search.run,
  description="Useful for search-based queries",
)

agent = Agent(
  role='Research Analyst',
  goal='Provide up-to-date market analysis',
  backstory='An expert analyst with a keen eye for market trends.',
  tools=[serper_tool]
)

# rest of the code ...
Conclusion¶
Tools are pivotal in extending the capabilities of CrewAI agents, enabling them to undertake a broad spectrum of tasks and collaborate effectively. When building solutions with CrewAI, leverage both custom and existing tools to empower your agents and enhance the AI ecosystem. Consider utilizing error handling, caching mechanisms, and the flexibility of tool arguments to optimize your agents' performance and capabilities.
Using LlamaIndex Tools
Using LlamaIndex Tools¶
LlamaIndex Integration

CrewAI seamlessly integrates with LlamaIndex’s comprehensive toolkit for RAG (Retrieval-Augmented Generation) and agentic pipelines, enabling advanced search-based queries and more. Here are the available built-in tools offered by LlamaIndex.


from crewai import Agent
from crewai_tools import LlamaIndexTool

# Example 1: Initialize from FunctionTool
from llama_index.core.tools import FunctionTool

your_python_function = lambda ...: ...
og_tool = FunctionTool.from_defaults(your_python_function, name="<name>", description='<description>')
tool = LlamaIndexTool.from_tool(og_tool)

# Example 2: Initialize from LlamaHub Tools
from llama_index.tools.wolfram_alpha import WolframAlphaToolSpec
wolfram_spec = WolframAlphaToolSpec(app_id="<app_id>")
wolfram_tools = wolfram_spec.to_tool_list()
tools = [LlamaIndexTool.from_tool(t) for t in wolfram_tools]

# Example 3: Initialize Tool from a LlamaIndex Query Engine
query_engine = index.as_query_engine()
query_tool = LlamaIndexTool.from_query_engine(
    query_engine,
    name="Uber 2019 10K Query Tool",
    description="Use this tool to lookup the 2019 Uber 10K Annual Report"
)

# Create and assign the tools to an agent
agent = Agent(
    role='Research Analyst',
    goal='Provide up-to-date market analysis',
    backstory='An expert analyst with a keen eye for market trends.',
    tools=[tool, *tools, query_tool]
)

# rest of the code ...
Steps to Get Started¶
To effectively use the LlamaIndexTool, follow these steps:

Package Installation: Confirm that the crewai[tools] package is installed in your Python environment.


pip install 'crewai[tools]'
Install and Use LlamaIndex: Follow the LlamaIndex documentation LlamaIndex Documentation to set up a RAG/agent pipeline.



